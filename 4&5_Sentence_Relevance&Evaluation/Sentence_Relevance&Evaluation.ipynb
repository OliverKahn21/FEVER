{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Subtask4_5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "oI0FqFdGhg3n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Subtask4"
      ]
    },
    {
      "metadata": {
        "id": "tRFetmJshitg",
        "colab_type": "code",
        "outputId": "497a9145-1b65-45e1-9a00-bb6157ad5ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "import re\n",
        "from fever_io import load_dataset_json\n",
        "from math import *\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "I9OlgB2ehkeW",
        "colab_type": "code",
        "outputId": "60031f81-6064-45f6-dccd-9c65ea9a6a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fWe_0tq64vIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = '/content/gdrive/My Drive/IRDM_CHFX2/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PaUeCL0gtxJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(inX):\n",
        "    '''\n",
        "    This Sigmoid function is used as a threshold function and mapping variables to between 0 and 1.\n",
        "    '''\n",
        "    if inX < 0:\n",
        "        return 1 - 1/(1 + exp(inX))\n",
        "    else:\n",
        "        return 1/(1 + exp(-inX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4i4_2p2t1yL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def loadtrainData():\n",
        "     '''\n",
        "     This funtion is used to read the training data without any sampling.\n",
        "     I tried the performance of this method and because of the negative result I do not use it in the final model.\n",
        "     '''\n",
        "#    train_x = []\n",
        "#    train_y = []\n",
        "#    fileIn = open(PATH + 'traindata_Subtask4.txt')\n",
        "#    for line in fileIn.readlines():\n",
        "#        lineArr = line.strip().split()\n",
        "#        train_x.append([float(lineArr[i]) for i in range(len(lineArr) - 1)])\n",
        "#        train_y.append(int(lineArr[-1]))\n",
        "#    return np.mat(train_x), np.mat(train_y).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01HcVMfXkWK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def loadtrainData_oversampling():\n",
        "     '''\n",
        "     This funtion is used to read the training data with over sampling.\n",
        "     I tried the performance of this method and because of the negative result I do not use it in the final model.\n",
        "     '''\n",
        "#    pre_x = []\n",
        "#    pre_y = []\n",
        "#    fileIn = open(PATH + 'traindata_Subtask4.txt')\n",
        "#    for line in fileIn.readlines():\n",
        "#        lineArr = line.strip().split()\n",
        "#        pre_x.append([float(lineArr[i]) for i in range(len(lineArr) - 1)])\n",
        "#        pre_y.append(int(lineArr[-1]))\n",
        "#    ros = RandomOverSampler(random_state=0)\n",
        "#    sampl_x, sampl_y = ros.fit_sample(pre_x, pre_y)\n",
        "#    return np.mat(sampl_x),np.mat(sampl_y).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoxBy47LpHEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loadtrainData_undersampling():\n",
        "    '''\n",
        "    This funtion is used to read the training data with under sampling.\n",
        "    In my training set, it including 153 positive samples and 3201 negative samples. By using this function, we can get all the positive samples and the same number of negative samples.\n",
        "    '''\n",
        "    train = []\n",
        "    fileIn = open(PATH + 'traindata_Subtask4.txt')\n",
        "    for line in fileIn.readlines():\n",
        "        lineArr = line.strip().split()\n",
        "        train.append([float(lineArr[i]) for i in range(len(lineArr))])\n",
        "   \n",
        "    pos = []\n",
        "    neg = []\n",
        "    for i in train:\n",
        "        if i[-1] == 1.0:\n",
        "            pos.append(i)\n",
        "        else:\n",
        "            neg.append(i)\n",
        "    slice1 = random.sample(neg, len(pos))\n",
        "    data = pos + slice1\n",
        "    train_x=[]\n",
        "    train_y=[]\n",
        "    y = []\n",
        "    for line in data:\n",
        "        train_x.append([float(line[i]) for i in range(len(line)-1)])\n",
        "        y.append([int(line[-1])])\n",
        "    for i in range(len(y)):\n",
        "        train_y.append(y[i][0])\n",
        "    return np.mat(train_x), np.mat(train_y).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJF95x3jt5BS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loaddevData():\n",
        "    '''\n",
        "    This funtion is used to read the top 10 claims in the dev set.\n",
        "    ''' \n",
        "    dev_x = []\n",
        "    dev_y = []\n",
        "    fileIn = open(PATH + 'devdata_Subtask4.txt')\n",
        "    for line in fileIn.readlines():\n",
        "        lineArr = line.strip().split()\n",
        "        dev_x.append([float(lineArr[i]) for i in range(len(lineArr) - 1)])\n",
        "        dev_y.append(int(lineArr[-1]))\n",
        "    return np.mat(dev_x), np.mat(dev_y).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-AG6qtEt9TO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainLogRegres(train_x, train_y, opts):\n",
        "    '''\n",
        "    This function is the logistic regresion model with stochastic gradient descent.\n",
        "    The input is the train_x, the label 'train_y' and the smooth method. I tried two different method in the model.\n",
        "    The output is the weights that using for prediciton and I also print the train loss and training time to analyse the effect of learning rate.\n",
        "    '''\n",
        "    startTime = time.time() ## calculate training time\n",
        "\n",
        "    numSamples, numFeatures = np.shape(train_x)\n",
        "    alpha = opts['alpha']\n",
        "    maxIter = opts['maxIter']\n",
        "    weights = np.ones((numFeatures, 1))\n",
        "\n",
        "\n",
        "    for k in range(maxIter):\n",
        "        if opts['optimizeType'] == 'stocGradDescent':  ## stochastic gradient descent\n",
        "            for i in range(numSamples):\n",
        "                output = sigmoid(train_x[i, :] * weights)\n",
        "                loss = train_y[i, 0] - output\n",
        "                weights = weights + alpha * train_x[i, :].transpose() * loss\n",
        "        elif opts['optimizeType'] == 'smoothStocGradDescent':  ## smooth stochastic gradient descent. randomly select samples to optimize for reducing cycle fluctuations.\n",
        "            dataIndex = list(range(numSamples))\n",
        "            for i in range(numSamples):\n",
        "                alpha = 4.0 / (1.0 + k + i) + 0.01\n",
        "                randIndex = int(np.random.uniform(0, len(dataIndex)))\n",
        "                output = sigmoid(train_x[randIndex, :] * weights)\n",
        "                loss = train_y[randIndex, 0] - output\n",
        "                weights = weights + alpha * train_x[randIndex, :].transpose() * loss\n",
        "                del (dataIndex[randIndex])\n",
        "    print(loss)\n",
        "    print('Congratulations, training complete! Took %fs!' % (time.time() - startTime))\n",
        "    return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VR33p_6CuDP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def testLogRegres(weights, dev_x, dev_y):\n",
        "    '''\n",
        "    This function is used to predict the data by the logistice model.\n",
        "    The input is the weights of logistics model, the dev_x and the label 'dev_y'.\n",
        "    The output is the prediction result.\n",
        "    '''\n",
        "    predict_y = []\n",
        "    numSamples, numFeatures = np.shape(dev_x)\n",
        "    for i in range(numSamples):\n",
        "        if sigmoid(dev_x[i, :] * weights) > 0.5:\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "        predict_y.append(label)\n",
        "    print('Congratulations, testing complete!')\n",
        "    return predict_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0jnJy4SUhk1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_train_1(path):\n",
        "    '''\n",
        "    This function is the same as the function for data pre-processing for query-likelihood unigram language model in Subtask3.\n",
        "    '''\n",
        "    n_dict = {}\n",
        "    files = os.listdir(path)\n",
        "    for i in files:\n",
        "        with open(os.path.join(path, i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                text = eval(line)['text'] ## extract data from the field of 'text'.\n",
        "                words = text.split(' ')\n",
        "                for w in words:\n",
        "                    w = w.replace(\"-LRB-\",\"\").replace(\"-RRB-\",\"\").replace(\"-LSB-\",\"\").replace(\"-RSB-\",\"\").replace(\"--\",\"\")\n",
        "                    w = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", w) ## replace the noisy with space. \n",
        "                    if not w in n_dict:\n",
        "                        n_dict[w] = 1\n",
        "                    else:\n",
        "                        n_dict[w] += 1 ## count the frequencies of every term.\n",
        "    np.save(PATH + \"pre_train_1_Subtask4.npy\",n_dict)\n",
        "    print ('save complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rBBIDAGNhvFk",
        "colab_type": "code",
        "outputId": "83c6d5ce-8881-4fe3-fe59-5fd7ccd79a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_train_1(PATH + 'data/wiki-pages/wiki-pages/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "save complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z6P6Syd5hxGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_train_2_Laplace(number):\n",
        "    '''\n",
        "    This function is the same as the function for Laplace Smoothing query-likelihood unigram language model in Subtask3.\n",
        "    '''\n",
        "    alpha = 0.5\n",
        "\n",
        "    train_data = load_dataset_json(PATH + 'data/train.jsonl', instance_num = number)\n",
        "    data = np.load(PATH + 'pre_train_1_Subtask4.npy', allow_pickle=True).item()\n",
        "    \n",
        "    id_list = []\n",
        "    for d in train_data:\n",
        "        if d['label'] != 'NOT ENOUGH INFO':\n",
        "            claim_id = d['id']\n",
        "            id_list.append(claim_id)\n",
        "\n",
        "    documents ={}\n",
        "    for x in id_list:\n",
        "        claim = None\n",
        "        for d in train_data:\n",
        "            if d['id'] == x:\n",
        "                claim = d['claim'][:-1]\n",
        "                claim = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "                claim = claim.split(' ')\n",
        "                #break\n",
        "\n",
        "                C = sum(data.values())\n",
        "                f = []\n",
        "\n",
        "                files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "                for i in files:\n",
        "                    with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "                        lines = fp.readlines()\n",
        "                        for line in lines:\n",
        "                            text = eval(line)['text'].split(' ')\n",
        "                            tmp = 0\n",
        "                            for w in claim:\n",
        "                                if w in text:\n",
        "                                    p = (text.count(w) + 1) / (len(text) + 1)\n",
        "                                else:\n",
        "                                    if w in data:\n",
        "                                        p = alpha * (data[w] + 1) / (C + len(data))\n",
        "                                    else:\n",
        "                                        p = 0.01\n",
        "                                tmp += log(p)\n",
        "                            f.append((eval(line)['id'], tmp))\n",
        "                f.sort(key=lambda x:x[1], reverse=True)\n",
        "                evidence = []\n",
        "                for i in range(5):\n",
        "                    name = f[i][0]\n",
        "                    evidence.append(name)\n",
        "                documents[d['claim']] = evidence\n",
        "    np.save(PATH + \"pre_train_2_Subtask4.npy\",documents)\n",
        "    print ('save complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fxvb4TLfsf6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_train_2_Laplace(150)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXV2VS3Oh1II",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_train_3():\n",
        "    '''\n",
        "    The output is a dictionary which the key is the document 'id' that appear in any of the claim's five similar documents and the value is 'lines' in wiki-pages.\n",
        "    '''\n",
        "    train_data = np.load(PATH + 'pre_train_2_Subtask4.npy', allow_pickle=True).item()\n",
        "\n",
        "    evidence=[]\n",
        "    for d in train_data.items():\n",
        "        for i in range(5):\n",
        "            evidence.append(d[1][i])\n",
        "\n",
        "    files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "    documents = {}\n",
        "    for i in files:\n",
        "        with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                line = eval(line)\n",
        "                if line['id'] in evidence:\n",
        "                    text = line['lines']\n",
        "                    documents[line['id']] = text\n",
        "    with open(PATH + 'pre_train_3_Subtask4.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(str(documents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgWL8bAxh3wI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_train_3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gURzq35kh5Gt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_train_4():\n",
        "    '''\n",
        "    The output is a list which the structure is [claim, evidence document, sentence_number].\n",
        "    '''\n",
        "    evidence_data = load_dataset_json(PATH + 'data/train.jsonl', instance_num = 200)\n",
        "    evi = []\n",
        "    for i in evidence_data:\n",
        "        for j in i['evidence']:\n",
        "            evi.append([i['claim'], j[0][2], j[0][3]])\n",
        "    evi_new=[]\n",
        "    for e in evi:\n",
        "        if e not in evi_new:\n",
        "            evi_new.append(e)\n",
        "    \n",
        "    with open(PATH + 'pre_train_4_Subtask4.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(str(evi_new))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEVizfpDiBZI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_train_4()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MmF-nQ_qiCgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_train_5():\n",
        "    '''\n",
        "    The out put is the embedding result of claim, sentence and the label which is totally 601 dimmensions\n",
        "    I use word2vec for embedding and the structure of output for each claim and the sentence is [embedding claim_300 dimmensions, embedding each sentence in 5 documents_300 dimmensions, label]\n",
        "    If the sentence is the evidence sentence show in the train set, the label is 1. Else the label is 0.\n",
        "    '''\n",
        "    with open(PATH + 'pre_train_4_Subtask4.txt', encoding='utf-8') as fi:\n",
        "        evi = eval(fi.read())\n",
        "\n",
        "    train_data = np.load(PATH + 'pre_train_2_Subtask4.npy', allow_pickle=True).item()\n",
        "    model = word2vec.KeyedVectors.load_word2vec_format(PATH + \"data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
        "\n",
        "    with open(PATH + 'pre_train_3_Subtask4.txt', encoding='utf-8') as f:\n",
        "        document = eval(f.read())\n",
        "\n",
        "    with open(PATH + 'traindata_Subtask4.txt', 'w') as fp:\n",
        "        for data in train_data.items():\n",
        "                claim = data[0]\n",
        "                claim = re.sub(\"[-,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "                claim = claim.split(' ')\n",
        "                claim = list(filter(lambda x: x in model.vocab, claim))\n",
        "                Vi = []\n",
        "                for i in range(len(claim)):\n",
        "                    Vi.append(model[claim[i]])\n",
        "\n",
        "                V = np.zeros(len(Vi[0]))\n",
        "                for i in range(len(claim)):\n",
        "                    for j in range(len(Vi[0])):\n",
        "                        V[j] = V[j] + Vi[i][j]\n",
        "\n",
        "                rms = 0\n",
        "                for i in range(len(Vi[0])):\n",
        "                    rms += V[i] * V[i]\n",
        "                rms = np.sqrt(rms / len(Vi[0]))\n",
        "\n",
        "                for i in range(len(Vi[0])):\n",
        "                    V[i] = V[i] / rms\n",
        "                V = V.astype(str).tolist()\n",
        "                \n",
        "                for doc in data[1]:\n",
        "                    lines = document[doc].split('\\n')\n",
        "                    for k in range(len(lines)):\n",
        "                        label = [data[0], doc, k]\n",
        "                        line = document[doc].split('\\n')[k]\n",
        "                        if line != str(k) + '\\t':\n",
        "                            line = line.replace(str(k) + '\\t', '')\n",
        "                            line = line.split('\\t')[0]\n",
        "                            line = re.sub(\"[-,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", line)\n",
        "                            line = line.split(' ')\n",
        "                            line = list(filter(lambda x: x in model.vocab, line))\n",
        "                            if len(line) != 0:\n",
        "                                Vi = []\n",
        "                                for i in range(len(line)):\n",
        "                                    Vi.append(model[line[i]])\n",
        "\n",
        "                                V1 = np.zeros(len(Vi[0]))\n",
        "                                for i in range(len(line)):\n",
        "                                    for j in range(len(Vi[0])):\n",
        "                                        V1[j] = V1[j] + Vi[i][j]\n",
        "\n",
        "                                rms = 0\n",
        "                                for i in range(len(Vi[0])):\n",
        "                                    rms += V1[i] * V1[i]\n",
        "                                rms = np.sqrt(rms / len(Vi[0]))\n",
        "\n",
        "                                for i in range(len(Vi[0])):\n",
        "                                    V1[i] = V1[i] / rms\n",
        "                                V1 = V1.astype(str).tolist()\n",
        "                                \n",
        "                                if label in evi:\n",
        "                                    fp.write(' '.join(V) + ' ' + ' '.join(V1) + ' 1' + '\\n')\n",
        "                                else:\n",
        "                                    fp.write(' '.join(V) + ' ' + ' '.join(V1) + ' 0' + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xNswkB-Fukno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_train_5()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOQDpBbjr4k0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### For the following 4 funtions, they are the same as the above 4 functions. The only different is that it is for the 10 claims in the development set."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIhR1VjVuKYz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_dev_2_Laplace(index):\n",
        "    alpha = 0.5\n",
        "\n",
        "    dev_data = load_dataset_json(PATH + 'data/dev.jsonl', instance_num=20)\n",
        "    data = np.load(PATH + 'pre_train_1_Subtask4.npy', allow_pickle=True).item()\n",
        "    \n",
        "    documents ={}\n",
        "    index_list = index\n",
        "    for x in index_list:\n",
        "        claim = None\n",
        "        for d in dev_data:\n",
        "            if d['id'] == x:\n",
        "                claim = d['claim'][:-1]\n",
        "                claim = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "                claim = claim.split(' ')\n",
        "                #break\n",
        "\n",
        "                C = sum(data.values())\n",
        "                f = []\n",
        "\n",
        "                files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "                for i in files:\n",
        "                    with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "                        lines = fp.readlines()\n",
        "                        for line in lines:\n",
        "                            text = eval(line)['text'].split(' ')\n",
        "                            tmp = 0\n",
        "                            for w in claim:\n",
        "                                if w in text:\n",
        "                                    p = (text.count(w) + 1) / (len(text) + 1)\n",
        "                                else:\n",
        "                                    if w in data:\n",
        "                                        p = alpha * (data[w] + 1) / (C + len(data))\n",
        "                                    else:\n",
        "                                        p = 0.01\n",
        "                                tmp += log(p)\n",
        "                            f.append((eval(line)['id'], tmp))\n",
        "                f.sort(key=lambda x:x[1], reverse=True)\n",
        "                evidence = []\n",
        "                for i in range(5):\n",
        "                    name = f[i][0]\n",
        "                    evidence.append(name)\n",
        "                documents[d['claim']] = evidence\n",
        "    np.save(PATH + \"pre_dev_2_Subtask4.npy\",documents)\n",
        "    print ('save complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q76geQFliFgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index = [\n",
        "137334,\n",
        "111897,\n",
        "89891,\n",
        "181634,\n",
        "219028,\n",
        "108281,\n",
        "204361,\n",
        "54168,\n",
        "105095,\n",
        "18708\n",
        "]\n",
        "\n",
        "Subtask4_pre_dev_2_Laplace(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CD9qaytjutPf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_dev_3():\n",
        "    dev_data = np.load(PATH + 'pre_dev_2_Subtask4.npy', allow_pickle=True).item()\n",
        "\n",
        "    evidence=[]\n",
        "    for d in dev_data.items():\n",
        "        for i in range(5):\n",
        "            evidence.append(d[1][i])\n",
        "\n",
        "    files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "    documents = {}\n",
        "    for i in files:\n",
        "        with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                line = eval(line)\n",
        "                if line['id'] in evidence:\n",
        "                    text = line['lines']\n",
        "                    documents[line['id']] = text\n",
        "    with open(PATH + 'pre_dev_3_Subtask4.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(str(documents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o79aV4Qyu88G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_dev_3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_BLukMXvIsT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_dev_4():\n",
        "    evidence_data = load_dataset_json(PATH + 'data/dev.jsonl', instance_num = 20)\n",
        "    evi = []\n",
        "    for i in evidence_data:\n",
        "        for j in i['evidence']:\n",
        "            evi.append([i['claim'], j[0][2], j[0][3]])\n",
        "    evi_new=[]\n",
        "    for e in evi:\n",
        "        if e not in evi_new:\n",
        "            evi_new.append(e)\n",
        "    \n",
        "    with open(PATH + 'pre_dev_4_Subtask4.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(str(evi_new))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eEt5K8Pxvc6a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_dev_4()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9rnmbiYvpPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask4_pre_dev_5():\n",
        "    with open(PATH + 'pre_dev_4_Subtask4.txt', encoding='utf-8') as fi:\n",
        "        evi = eval(fi.read())\n",
        "\n",
        "    train_data = np.load(PATH + 'pre_dev_2_Subtask4.npy', allow_pickle=True).item()\n",
        "    model = word2vec.KeyedVectors.load_word2vec_format(PATH + \"data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
        "\n",
        "    with open(PATH + 'pre_dev_3_Subtask4.txt', encoding='utf-8') as f:\n",
        "        document = eval(f.read())\n",
        "\n",
        "    with open(PATH + 'devdata_Subtask4.txt', 'w') as fp:\n",
        "        for data in train_data.items():\n",
        "                claim = data[0]\n",
        "                claim = re.sub(\"[-,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "                claim = claim.split(' ')\n",
        "                claim = list(filter(lambda x: x in model.vocab, claim))\n",
        "                Vi = []\n",
        "                for i in range(len(claim)):\n",
        "                    Vi.append(model[claim[i]])\n",
        "\n",
        "                V = np.zeros(len(Vi[0]))\n",
        "                for i in range(len(claim)):\n",
        "                    for j in range(len(Vi[0])):\n",
        "                        V[j] = V[j] + Vi[i][j]\n",
        "\n",
        "                rms = 0\n",
        "                for i in range(len(Vi[0])):\n",
        "                    rms += V[i] * V[i]\n",
        "                rms = np.sqrt(rms / len(Vi[0]))\n",
        "\n",
        "                for i in range(len(Vi[0])):\n",
        "                    V[i] = V[i] / rms\n",
        "                V = V.astype(str).tolist()\n",
        "                \n",
        "                for doc in data[1]:\n",
        "                    lines = document[doc].split('\\n')\n",
        "                    for k in range(len(lines)):\n",
        "                        label = [data[0], doc, k]\n",
        "                        line = document[doc].split('\\n')[k]\n",
        "                        if line != str(k) + '\\t':\n",
        "                            line = line.replace(str(k) + '\\t', '')\n",
        "                            line = line.split('\\t')[0]\n",
        "                            line = re.sub(\"[-,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", line)\n",
        "                            line = line.split(' ')\n",
        "                            line = list(filter(lambda x: x in model.vocab, line))\n",
        "                            if len(line) != 0:\n",
        "                                Vi = []\n",
        "                                for i in range(len(line)):\n",
        "                                    Vi.append(model[line[i]])\n",
        "\n",
        "                                V1 = np.zeros(len(Vi[0]))\n",
        "                                for i in range(len(line)):\n",
        "                                    for j in range(len(Vi[0])):\n",
        "                                        V1[j] = V1[j] + Vi[i][j]\n",
        "\n",
        "                                rms = 0\n",
        "                                for i in range(len(Vi[0])):\n",
        "                                    rms += V1[i] * V1[i]\n",
        "                                rms = np.sqrt(rms / len(Vi[0]))\n",
        "\n",
        "                                for i in range(len(Vi[0])):\n",
        "                                    V1[i] = V1[i] / rms\n",
        "                                V1 = V1.astype(str).tolist()\n",
        "\n",
        "                                if label in evi:\n",
        "                                    fp.write(' '.join(V) + ' ' + ' '.join(V1) + ' 1' + '\\n')\n",
        "                                else:\n",
        "                                    fp.write(' '.join(V) + ' ' + ' '.join(V1) + ' 0' + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2S7RYrhv1DB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Subtask4_pre_dev_5()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZWhQzGzhX9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "The result below use the undersampling method and save as 'train_x.dat' and 'train_y.dat'.\n",
        "You may not get the same result if you sampling again because the sampling result is different every time.\n",
        "As an alternative, you need to use the following code to read the sampling data I saved after got the best result to reproduce the result\n",
        "code:\n",
        "'''\n",
        "print(\"step 1: load data...\")\n",
        "train_x = np.load(PATH + 'train_x.dat', allow_pickle=True)\n",
        "train_y = np.load(PATH + 'train_y.dat', allow_pickle=True)\n",
        "dev_x, dev_y = loaddevData()\n",
        "\n",
        "print(\"step 2: training...\")\n",
        "opts = {'alpha': 0.0001, 'maxIter': 5000, 'optimizeType': 'smoothStocGradDescent'}\n",
        "optimalWeights = trainLogRegres(train_x, train_y, opts)\n",
        "\n",
        "print(\"step 3: testing...\")\n",
        "predict_y = testLogRegres(optimalWeights, dev_x, dev_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hJfXWD7K70U",
        "colab_type": "code",
        "outputId": "78323df5-1870-4472-b4b8-095e0dfbab3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "This part is using to load the train data, dev data and training the model and prediction the result.\n",
        "I used it to try different sampling method and the best result is show below and the data sampling for this result is save as 'train_x.dat' and 'train_y.dat'\n",
        "Please use the code above to read the undersampling data to reproduce the result below because the sampling result is different every time and you may not get the same result if you sampling again.\n",
        "'''\n",
        "# ## step 1: load data\n",
        "# print(\"step 1: load data...\")\n",
        "# train_x, train_y = loadtrainData_undersampling()\n",
        "# dev_x, dev_y = loaddevData()\n",
        "# ## step 2: training\n",
        "# print(\"step 2: training...\")\n",
        "# opts = {'alpha': 0.0001, 'maxIter': 5000, 'optimizeType': 'smoothStocGradDescent'}\n",
        "# optimalWeights = trainLogRegres(train_x, train_y, opts)\n",
        "# ## step 3: testing\n",
        "# print(\"step 3: testing...\")\n",
        "# predict_y = testLogRegres(optimalWeights, dev_x, dev_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 1: load data...\n",
            "step 2: training...\n",
            "2.4976221091321804e-09\n",
            "Congratulations, training complete! Took 97.173146s!\n",
            "step 3: testing...\n",
            "Congratulations, testing complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ns9-Lx96GX0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, mean_squared_error, accuracy_score, zero_one_loss\n",
        "import matplotlib.pyplot as plt\n",
        "def check_fit(truth, prob):\n",
        "    '''\n",
        "    This function is using the plot the ROC curve and print the RMSE, accuracy, AUC and test loss.\n",
        "    The input is the prediction result of dev data and the label of dev data\n",
        "    '''\n",
        "    fpr, tpr, _ = roc_curve(truth, prob)     ## drop_intermediate:(default=True) \n",
        "    roc_auc = auc(fpr, tpr)   ## calculate the AUC\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([-0.1, 1.05])\n",
        "    plt.ylim([-0.1, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show() \n",
        "    print('results are RMSE, accuracy, ROC, loss function')\n",
        "    print(sqrt(mean_squared_error(truth, prob)), accuracy_score(truth, prob), roc_auc,zero_one_loss(truth,prob))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KOQdzdiOKJA7",
        "colab_type": "code",
        "outputId": "f1671e4a-9310-436c-c916-7f33eb2757b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "check_fit(dev_y, predict_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4FNXXwPHvSYEk9A4m9F6kGZqo\n9F6kKnYBRVCKooL+7NheGyCIShUbojSJGFooAkoLgkgHaSH0kpBAeu77x2ySTYBkA9lsEs7neXjY\nnXpmsrtn7r0z94oxBqWUUgrAzdUBKKWUyjk0KSillEqmSUEppVQyTQpKKaWSaVJQSimVTJOCUkqp\nZJoU8gAReUREVrg6DlcTkQoiEiki7tm4z0oiYkTEI7v26UwisltEWt/Eenn2MygirUXkhKvjyC6a\nFLKYiBwVkSjbj9NpEZktIgWduU9jzI/GmI7O3EdOZDvX7ZPeG2OOG2MKGmMSXBmXq9iSU7Vb2YYx\npq4xZm0G+7kmEd6un8G8SJOCc/QwxhQEGgKNgFddHM9NceXVb1658s4MPd8qJ9Ck4ETGmNPAcqzk\nAICI5BeRT0XkuIicEZGvRcTbbv79IrJDRC6LyH8i0tk2vYiIzBSRUyISKiLvJVWTiMiTIrLB9vor\nEfnUPg4RWSwio22v7xCRBSJyTkSOiMhIu+XeFpH5IvKDiFwGnkx7TLY4vrOtf0xEXhcRN7s4/hSR\nL0QkXET2iUi7NOumdwx/isgEEbkAvC0iVUVktYhcEJHzIvKjiBS1Lf89UAH4zVYqG5P2ClZE1orI\nu7btRojIChEpaRfP47ZjuCAib6QteaQ5bm8R+cy2fLiIbLD/uwGP2P6m50XkNbv1morIRhEJsx33\nFyKSz26+EZHnROQgcNA27XMRCbF9BraJyL12y7uLyP9sn40I2/zyIrLOtsg/tvPxoG357rbPU5iI\n/CUi9e22dVRExorITuCKiHjYnwNb7MG2OM6IyHjbqkn7CrPtq4X9Z9C2bl0RWSkiF23r/u8G5/WG\n3wdbbJvt/p7DxKre8rK9nydWaTxcRNaJSF277c4WkS9FZKktxj9FpKyITBSRS7bPZqM05+JVEdlj\nm/9N0n6uE/MNv0N5gjFG/2XhP+Ao0N722g/4F/jcbv4EIAAoDhQCfgM+tM1rCoQDHbASti9QyzZv\nETAVKACUBrYAz9jmPQlssL2+DwgBxPa+GBAF3GHb5jbgTSAfUAU4DHSyLfs2EAf0si3rfZ3j+w5Y\nbIu9EnAAGGwXRzzwAuAJPGg7nuIOHkM8MALwALyBarZzkR8ohfVjNPF659r2vhJgAA/b+7XAf0AN\n2/bWAv9nm1cHiATusZ2LT23H3v4Gf9cptvV9AXfgbltcSfucbttHAyAGqG1b7y6gue2YKgF7geft\ntmuAlVifB2/btEeBErZ1XgROA162eS9jfaZqAmLbXwm7bVWz23Yj4CzQzBbzE7Zzlt/u/O0Aytvt\nO/mcAhuBx2yvCwLNr3eer/MZLAScssXuZXvf7AbnNb3vg5vtb/42UB24BDSyW3eQbZ38wERgh928\n2cB52/n3AlYDR4DHbefiPWBNms/SLtu5KA78Cbxnm9caOGEX0w2/Q3nhn8sDyGv/bB+uSCDC9sVZ\nBRS1zRPgClDVbvkWwBHb66nAhOtsswzWD4233bSHkj7Uab6QAhwH7rO9fxpYbXvdDDieZtuvAt/Y\nXr8NrEvn2NyBWKCO3bRngLV2cZzElpBs07YAjzl4DMdvtG/bMr2A7WnOdUZJ4XW7+c8Cy2yv3wR+\nspvnYzu2a5KC7YcgCmhwnXlJ+/RLc8wDbnAMzwOL7N4boG0Gx30pad/AfuD+GyyXNil8BbybZpn9\nQCu78zfoOp/fpKSwDngHKHmDY75RUnjI/u+UznGl+32w29dFrGT6ajrbKmqLqYjt/Wxgut38EcBe\nu/d3AmFpjnuo3fuuwH+2161JSQrpfofywj+tR3SOXsaYIBFpBcwBSgJhWFe7PsA2EUlaVrB+bMG6\nSgm8zvYqYl15n7Jbzw2rRJCKMcaIyFysL+Y64GHgB7vt3CEiYXaruAPr7d5fs007JW1xHLObdgzr\n6jlJqLF9U+zm3+HgMaTat4iUAT4H7sW6InTD+oHMjNN2r69iXfFiiyl5f8aYq2JVW11PSayrzf8y\nux8RqQGMB/yx/vYeWFea9tIe90vAYFuMBihsiwGsz0h6cdirCDwhIiPspuWzbfe6+05jMDAO2Cci\nR4B3jDFLHNivozFm9H3AGHNURNZg/UhPSV7IqnZ8H+hv206ibVZJrNIpwBm7fUVd533aG0Dsz0XS\n5zYtR75DuZq2KTiRMeYPrCuWpDr+81gfxrrGmKK2f0WM1SgN1oey6nU2FYJ1lV3Sbr3Cxpi611kW\n4Cegn4hUxLqyWWC3nSN22yhqjClkjOlqH3Y6h3Qeq4qlot20CkCo3XtfsfuG2+afdPAY0u77A9u0\nO40xhbGqVSSd5TPjFFb1HmC1GWBV2VzPeSCa6/9tMvIVsA+objuG/5H6GMDuOGztB2OAB4Bixpii\nWD9ySevc6DNyPSHA+2n+3j7GmJ+ut++0jDEHjTEPYVX1fQTMF5EC6a1jt98qDsSX0fcBEemGVXpY\nBXxit+7DwP1Ae6AIVokCrj23mVHe7nXS5zYtR75DuZomBeebCHQQkQbGmESsuucJIlIaQER8RaST\nbdmZwEARaScibrZ5tYwxp4AVwGciUtg2r6qtJHINY8x2rC/cDGC5MSbpqmYLEGFrwPO2NVrWE5Em\njhyIsW71/AV4X0QK2ZLOaFJKImD9gIwUEU8R6Q/UBgIzeww2hbCq4sJFxBerPt3eGRz78bme+UAP\nEblbrIbft7nBD4rt7zYLGG9rZHS3Na7md2A/hYDLQKSI1AKGObB8PHAO8BCRN7FKCklmAO+KSHWx\n1BeRpGSW9nxMB4aKSDPbsgVEpJuIFHIgbkTkUREpZTv+pM9Qoi22RG587pcA5UTkeVtDciERaZZ2\noYy+D2LdFDADeAqrPaSHiCT9+BbCusi4gFXa+MCRY8rAcyLiJyLFgdeAn6+zzC19h3IDTQpOZow5\nh9U4+6Zt0ljgELBJrDt8grAaDTHGbAEGYjW+hQN/kHJV/jhW0X8PVhXKfKBcOrueg3UVNcculgSg\nO9bdUEdISRxFMnFII7DqgQ8DG2zbn2U3fzNWo+B5rOJ9P2NMUrVMZo/hHaAx1rn4HViYZv6HwOti\n3VnzUiaOAWPMbtuxzMUqNURiNcrG3GCVl7AaeLdi1XF/hGPfn5ewrmojsH4Ar/dDY285sAyrAf8Y\nVgnFvlpjPFZiXoGVbGZiNXCDldi+tZ2PB4wxwVhtSl9gne9DXOeOsnR0BnaLSCRWNd4AY0yUMeYq\n1t/2T9u+mtuvZIyJwLpBoAdWtdpBoM0N9nHD7wMwDVhsjAm0fYYGAzNsSfA72/kJxfo8bcrEcd3I\nHKzzehir+uu9tAtk0XcoR0u6Q0WpWyYiTwJPGWPucXUsmSXWA4ZhWNU8R1wdj8peInIU67Mb5OpY\nXE1LCuq2JSI9RMTHVk/+KVZJ4Khro1LKtTQpqNvZ/ViNiSexqrwGGC06q9ucVh8ppZRKpiUFpZRS\nyXLdw2slS5Y0lSpVcnUYSimVq2zbtu28MaZURsvluqRQqVIlgoODXR2GUkrlKiJyLOOltPpIKaWU\nHU0KSimlkmlSUEoplUyTglJKqWSaFJRSSiVzWlIQkVkiclZEdt1gvojIJBE5JCI7RaSxs2JRSinl\nGGeWFGZj9bJ4I12wuhaoDgzB6ndeKaXU9cRdhaMrIC7Kqbtx2nMKxph1IlIpnUXuB76z9TWzSUSK\nikg5W7/7Sil1e0tMgDPb4HgQW1ZtZs+uUJ68axv0XQGVOjhtt658eM2X1P3En7BNuyYpiMgQrNIE\nFSpUyJbglFIqWxkDYYfg2Eo4FgQha7hy+QpvLm/DxPXN8XSvT4tGBaiZGOfUMHLFE83GmGlYA27g\n7++vPfgppfKGK2fg+Go4HmQlgojjybNWH6zM0wsHc/hcIdzcYNRIfyoMfxO8PZ0akiuTQiipx0T1\nI/VYv0oplbfERkLoeisBHA+CcztTz/cqQVjxDrw8vzEzFl4FoH79Msyc2RN//zuyJURXJoUAYLiI\nzMUaXD5c2xOUUnlKYjyc3pqSBE5uBPvqHw8v8L0PKraHCu2hdAOeGbCQXxbuJl8+d9544z7Gjm2J\np6d7toXstKQgIj8BrYGSInICeAvwBDDGfA0EAl2xxme9ijU2sVJK5V7GwMV9KUkgZC3EXk6ZL25Q\ntmlKErijhZUY7Lz3XhvOn7/K5MldqFMnw05Ns1yuG2TH39/faC+pSqkcI/IkHF+VkggiT6aeX6yG\nlQAqtofyrcGrWPIsYwxz5vzL778f5Mcf+yAiTgtTRLYZY/wzWi5XNDQrpVSOEXMZTvyRkgQu7Ek9\n36d0ShKo0A4KX/+OyZCQcIYO/Z3AwIMAPPLInXTrVsPZ0WdIk4JSSqUnIRZObU5JAqc2g0lIme9Z\nAPxapVQJlawH6VzxJyYapk4NZuzYICIiYilSJD/jx3eia9fq2XAwGdOkoJRS9oyBC7tTtwvEXUmZ\nL+5QroWVBCp2gHLNwD2fQ5s+ePACTz31G+vWWePd9OpViylTunLHHYWccCA3R5OCUkpdDrHaBZKe\nF7h6JvX84rVTSgLlW0H+Ije1mzlz/mXdumOULl2AKVO60rdvbae2I9wMTQpKqdtPdJhVAkhKApf2\np55foFxKEqjQDgr53vSurl6Nw8fHeuDslVfuISYmgZdeupvixb1v4QCcR5OCUirvi4+BUxtTqoRO\nbwWTmDI/XyHwa22rEmpvlQxu8Qo+Jiae995bxzff7OCff4ZSooQP+fN78MEH7W7tWJxMk4JSKu8x\nidbTwklJ4MQ6iLfrXdTNA+5omVIaKNsE3LOu+4iNG0MYPDiAvXvPA7B06SEefbR+lm3fmTQpKKXy\nhvCjKUng+CqIOp96fsk7U5KA332Qr2CWhxAZGcvrr69m0qTNGAM1apRgxowe3HtvxSzfl7NoUlBK\n5U5RFyBkTUoiCPsv9fyCftbdQRXbQ4W2UKCsU8NZt+4YTzzxK0ePhuHuLowZ05I332yFl1fu+pnN\nXdEqpW5f8dEQuiElCZz5G7DrkSF/ESjfNqU0UKz6LbcLZEZCQiJHj4bRsGFZZs3qSaNG5bJt31lJ\nk4JSKmdKTIBzO6wkcCwITm6wEkMS93xwx90pTw+XuctqK8hGO3acpmFDqwTSpk1lAgMfpn37Ktna\ngV1W06SglMoZjIHww3btAqsh+mLqZUo1TLlDyPce62liFzh9OpIRI5Yyf/4e1q59glatKgHQpUvO\neCr5VmhSUEq5ztVzqQeZuXw09fzCFa12gQq2dgGf7O811J4xhu+/38nzzy/j0qVoChTwJDQ0wqUx\nZTVNCkqp7BN3NWWQmWNBVvWQPa9i1sNiSVVCRapka7tAeo4dC+OZZ5awfLnVoN2xY1WmTu1OpUpF\nXRxZ1tKkoJRynsR4a/D55EFm/rI6mEvinh98702pEirVENxyXn18UNBhevf+mcjIWIoV82LChE48\n/niDHNdFRVbQpKCUyjrGwKUDdp3JrYGYcLsFBMr42w0yczd45szuHuw1bFgWb28POnWqyhdfdKVs\n2ax/xiGn0KSglLo1V07bDTKzCiJCUs8vWs2uM7k24F3cNXFmQlxcAjNnbmfQoEbky+dOyZI+7Ngx\nNEf1ZuosmhSUUpkTG2l1G3E8CI6thPO7Us/3Lmm1C1TsYP1fpJJLwrxZ27efYvDgALZvP82ZM5G8\n9VZrgNsiIYAmBaVURhLirA7kku4QOrXRaitI4uFtdRuR1Dhcqr41FnEuEx0dz7hxf/Dxx3+SkGCo\nWLEILVqUd3VY2U6TglIqNWPg4t6UO4ROrIVYu9suxc0aWCYpCZRrAR75XRZuVvjzz+MMHhzA/v0X\nEIGRI5vy/vvtKFjQscFz8hJNCkopiAhNPcjMlVOp5xeradcu0Bq88s5tmJs2neDee7/BGKhVqyQz\nZvSgZcvrj6t8O9CkoNTtKCYcQv5ISQIX96ae71Mm9SAzhfNuNUqzZr507lyNxo3L8frr9+W6Duyy\n2u199ErdLhJi4dSmlCqh01uuHXy+fOuUKqESdXPMQ2NZ7eLFKMaOXcmYMS2pXr0EIsKSJQ/j5pY3\njzezNCkolRcZY90VdGxlyiAzaQeftx9kplxThwefz83mz9/Dc88FcvbsFUJCLrNs2aMAmhDsaFJQ\nKq+4fNzueYEguHo29fwSdVMPMpO/sGvidIFTpyIYPnwpCxda1WT33luBSZO6uDiqnEmTglK5VfQl\na/D5pCRw6UDq+QXvSKkOqtDOen+bMcYwe/YORo9eQVhYNAUL5uOjj9ozdKi/lg5uQJOCUrlFfIzV\nd1BS4/CZ4GsHny/fJiURFK+VZ9sFHHXsWDjDhv1OTEwCnTtXY+rU7lSoUMTVYeVomhSUyqlMIpz9\nJyUJhK5PM/i8pzWmQFISKNsk2weZyYkSEw0iICJUqlSUTz7pQNGiXjz6aP082YFdVnPqJ0hEOgOf\nA+7ADGPM/6WZXwH4FihqW+YVY0ygM2NSKkcLP5Jyh9DxVRB9IfX8UvVTkoDvvU4ZfD4327v3HIMH\nBzBsmD+PPdYAgBEjmrk4qtzFaUlBRNyBKUAH4ASwVUQCjDF77BZ7HfjFGPOViNQBAoFKzopJqRwn\n6kLqQWbCD6eeX6h86kFmCpRxTZw5XFxcAh9//Cfjxq0jNjaBiIhYHnmkvrYb3ARnlhSaAoeMMYcB\nRGQucD9gnxQMkHQLRBHgpBPjUSpnOPsP7JtjJYGz20k9+HxR68c/qTRQtNpt3y6QkW3bTjJoUAA7\nd54BYPDgRnz6aUdNCDfJmUnBF7DvQ/cEkLYc9zawQkRGAAWA9k6MRynXO7IMFt+fMtCMe77U7QKl\nG+fIQWZyoujoeN5+ey2ffvoXCQmGypWLMn16D9q1q+Lq0HI1V7dKPQTMNsZ8JiItgO9FpJ4x9rdU\ngIgMAYYAVKhw+/ZJonK5oythcS8rIdR6COo+aRt83sfVkeVaixfvJzHR8MILzXn33TYUKJD3H8Bz\nNmcmhVDAvsMUP9s0e4OBzgDGmI0i4gWUBFI9dWOMmQZMA/D39zcoldscXw2Le0JCDDQYBu2maLXQ\nTbh8OQZjDEWKeOHl5cF33/UiIcHQvLmfq0PLM5zZ6flWoLqIVBaRfMAAICDNMseBdgAiUhvwAs45\nMSalsl/IH7CoO8RHw51PQ7svNCHchMDAg9Sr9yUvvLA8eVqTJr6aELKY00oKxph4ERkOLMe63XSW\nMWa3iIwDgo0xAcCLwHQReQGrte1JY4yWBFTecWI9LOpmPV9QdyB0+DpXDkDjSufPX+WFF5bzww87\nAdi16yxRUXF4e3u6OLK8yaltCrZnDgLTTHvT7vUeoKUzY1DKZUL/goVdrY7o6jwOHadrQsgEYwzz\n5u1h+PBAzp27ipeXB+++24bnn2+Oh4eeR2dxdUOzUnnTqc2wsDPERUKth6HTLL2rKBPi4xPp338e\nv/66D4BWrSoyY0ZPqlUr7uLI8j5NCkpltdPBML+jNYRlzQehy7eaEDLJw8ONkiW9KVQoH5980oGn\nn75LnzvIJpLbqvD9/f1NcHCwq8NQ6vrO/A3z2kFMGNToB91+0v6IHHT48CXCwqJp3LgcAGFh0URE\nxFC+vHZglxVEZJsxxj+j5bRiTqmscvYfmN/BSgjVekPXOZoQHJCQkMiECRupV+9LBgyYT1RUHABF\ni3ppQnAB/cQqlRXO/WuVEKIvQpUe0H0uuOvdMRnZvfssgwcHsHmz9QiTv/8dxMQk6J1FLqRJQalb\ndWGPLSFcgMpdoce822Joy1sRG5vA//3fBt57bx1xcYn4+hbiq6+60aNHTVeHdtvTpKDUrbiwD35p\nC1HnoGJH6LkAPPK7OqoczRhDly4/snr1EQCGDGnMxx93oEgRLxdHpkCTglI37+IBmNcWrp6xhru8\n/1fw0B+2jIgIgwc34tixMKZP70GbNpVdHZKyo0lBqZtx6RDMawNXTkH51tArADy9XR1VjrV27VH2\n7z/PM89YN7889FA9+vSpjZeX/gTlNPoXUSqzwg7DL20g8qQ1+lnvJdrT6Q2Eh0czZsxKpk37m3z5\n3GnVqhK1apVERDQh5FD6V1EqM8KP2hLCCbijJfT5HTwLuDqqHGnJkgMMHbqE0NAIPD3deO21e6lS\npZirw1IZ0KSglKMuh1htCBHHoVxz6BMI+Qq5Oqoc59y5K4watYyfftoFQNOmvsyc2ZN69Uq7ODLl\nCIeSgq3r6wrGmENOjkepnCki1GpDCD8CZZtA32WQv3DG692Gnn02kPnz9+Dt7cH777dl5MhmuLvr\nc7K5RYZJQUS6AeOBfEBlEWkIvGWM6e3s4JTKESJPWQkh7D8ocxf0XQH59UnbG/m//2tHVFQcn3/e\nmapVtQO73MaR9D0Oa2zlMABjzA6gmjODUirHuHLaqjK6dBBKNbQSgldRV0eVYyQmGqZN20bv3j+T\n1I9a1arFWbLkYU0IuZQj1UdxxpgwST1SVO7qRU+pm3H1rPWk8sV9UKo+9A8Cb/2hS3Lo0EWefvo3\n1q49CsCyZYfo0qW6a4NSt8yRpLBXRB4A3ESkMjAS2OTcsJRysavnrYRwYQ+UqAv9gsC7hKujyhHi\n4xOZOHETb7yxhujoeEqV8mHy5C507qwVCHmBI0lhOPAmkAgsxBpe83/ODEopl4q6APPbw/ldULwW\n9F8FPqVcHVWO8O+/Zxg8OICtW08C8Oij9ZkwoRMlS+pzGnmFI0mhkzFmLDA2aYKI9MFKEErlLdGX\nrO6vz/0DxWpA/9VQoIyro8oxFi/ez9atJ/HzK8zUqd3p2lWri/IaR5LC61ybAF67zjSlcrfoMGvE\ntLPboWg1KyEULOfqqFzu8uUYChe2OvkbM6YlxhhGjWqePE3lLTdMCiLSCegM+IrIeLtZhbGqkpTK\nO2LCYUEnOBMMRarAA2ugkK+ro3KpK1dieeONNfz447/s2jWMUqUKkC+fO2+80crVoSknSq+kcBbY\nBUQDu+2mRwCvODMopbJVbAQs6AKnt0DhSraE4OfqqFxq1arDPP30bxw5Eoabm7Bq1REGDKjn6rBU\nNrhhUjDGbAe2i8iPxpjobIxJqewTGwkLu8KpjVCogpUQCldwdVQuExYWzcsvr2DGjO0A1K9fhpkz\ne+Lvf4eLI1PZxZE2BV8ReR+oAyR3Fm+MqeG0qJTKDnFXYFF3CN0ABf3ggdVQpJKro3KZoKDDPPHE\nr5w8GWGrJrqPsWNb4unp7urQVDZyJCnMBt4DPgW6AAPRh9dUbhd3FX7tCSf+gIJ3WAmhaFVXR+VS\nXl4enDwZQfPmfsyc2ZM6dfQ23NuRI91c+BhjlgMYY/4zxryOlRyUyp3io2FxLzi+GgqUte4yKnb7\n3VppjGHjxpDk9/fcU4HVqx9nw4aBmhBuY44khRgRcQP+E5GhItID0P6CVe4UHwOLe8OxleBT2koI\nxW+/weKPHw+nW7c53H33LFatOpw8vU2bytqj6W3OkeqjF4ACWN1bvA8UAQY5MyilnCI+Bn7rC0eX\ngXdJKyGUqO3qqLJVYqJh6tRgxowJIjIylqJFvbh0Se8jUSkyTArGmM22lxHAYwAicnvfwK1yn4RY\nWPIgHP4dvIpbXVeUrOvqqLLVgQMXeOqpANavPw5A7961mDKlK+XKacFfpUi3nCgiTUSkl4iUtL2v\nKyLfAZvTW89u/c4isl9EDonIdZ9tEJEHRGSPiOwWkTmZPgKlMpIQB78/BP8tBq9iVud2peq7Oqps\ntXTpQRo0+Jr1649TunQB5s3rz4IFD2hCUNdI74nmD4G+wD/A6yKyBHgW+AgYmtGGRcQdmAJ0AE4A\nW0UkwBizx26Z6sCrQEtjzCUR0fH6VNZKjIfAR+DgQmtgnH4roUwjV0eV7Zo396NoUS86dqzK+PEd\nKVFCO7BT15de9dH9QANjTJSIFAdCgDuNMYfTWcdeU+BQ0vIiMte2zT12yzwNTDHGXAIwxpzN7AEo\ndUOJCbD0cTgwD/IVtgbIKXOXq6PKFjEx8UyZspVnn22Cl5cHxYp58++/w7Q3U5Wh9KqPoo0xUQDG\nmIvAgUwkBABfrESS5IRtmr0aQA0R+VNENolI5+ttSESGiEiwiASfO3cuEyGo21ZiAiwfCPt+gnyF\noO9yKNfU1VFli7/+CqFhw6m8+OIK3ntvXfJ0TQjKEemVFKqISFJPqII1PnNyz6jGmD5ZtP/qQGvA\nD1gnIncaY8LsFzLGTAOmAfj7++uDcyp9JhFWPAV7vgfPAtBnKdzR3NVROV1kZCyvvbaKyZO3YAzU\nqFFCB75RmZZeUuib5v0Xmdx2KFDe7r2fbZq9E8BmY0wccEREDmAlia2Z3JdSFpMIK5+B3bPBwwf6\nBIJvS1dH5XQrV/7HkCFLOHo0DHd3YcyYlrz5Ziu8vBy561ypFOl1iLfqFre9FahuG8IzFBgAPJxm\nmV+Bh4BvbHc41QAyU0WlVApjIOhZ+HcGeHhDn9/B7z5XR+V0f/0VQseOPwDQsGFZZs7sSePGOg6E\nujlOu4wwxsSLyHCs4TvdgVnGmN0iMg4INsYE2OZ1FJE9QALwsjHmgrNiUnmYMbB6BOycCh5e0Os3\nKN/a1VFlixYt/OjduxZNmtzBSy/drR3YqVsixuSuKnp/f38THBzs6jBUTmIMrH0B/v4c3PNBrwCo\n1MnVUTnNmTORjB69gjfeuI9atUoCVj9GIuLiyFROJiLbjDH+GS3ncElBRPIbY2JuLSylspgx8MdL\nVkJw84Sei/JsQjDG8N13//DCC8u5dCmaCxeusmzZowCaEFSWybDnKxFpKiL/Agdt7xuIyGSnR6ZU\nRoyB9a/AtvG2hLAAqnR1dVROcexYGF26/MiTTy7m0qVoOnWqytSp3V0dlsqDHCkpTAK6YzUKY4z5\nR0TaODUqpTJiDPz5Omz9GNw8oPvPULWHq6PKcomJhi+/3MorrwRx5UocxYp5MXFiZx57rL6WDpRT\nOJIU3Iwxx9J8ABOcFI9Sjtnm4vEtAAAgAElEQVT4Dmz+AMQduv0E1Xu7OiKnOH48nJdfXkl0dDz9\n+tXhiy+6UKZMQVeHpfIwR5JCiIg0BYytP6MRwAHnhqVUOja9ZyUFcYOuP0KNfq6OKEvFxyfi7i6I\nCJUqFeXzzztTsqQPffrcXt18K9dwZDSNYcBooAJwBmhum6ZU9tv8f/DnG1ZC6PI91HrQ1RFlqe3b\nT9G06XRmz96RPG3IkLs0Iahs40hSiDfGDDDGlLT9G2CMOe/0yJRKa+unsOFVQKDTN1A77bOQuVd0\ndDz/+98qmjSZzvbtp5k8eQuJibnrdnGVNzhSfbRVRPYDPwMLjTERTo5JqWttmwjrXrZed5oJdR93\nbTxZaMOG4zz1VAD7919ABEaNasZ777XFzU0bklX2c2TktaoicjdWNxXviMgOYK4xZq7To1MKYPsX\n1sNpAB2mQb2Bro0ni1y9GsfYsSuZMmUrxkDt2iWZObMnLVqUz3hlpZzEoRG6jTF/GWNGAo2By8CP\nTo1KqSQ7vrK6rwBo9yXUf9q18WQhDw831q49hru7G6+/fi/btz+jCUG5XIYlBREpiDU4zgCgNrAY\nuNvJcSkFO6fDqmet120mQcPcf3/DxYtRABQv7k2+fO58/31vRKBBg7IujkwpiyNtCruA34CPjTHr\nnRyPUpZ/Z8HKIdbr1uOh8QjXxpMFFizYw3PPBdKhQ1W+/956rqJhQ00GKmdxJClUMcYkOj0SpZLs\n/s4aJAfgvk/grhdcG88tOnUqguHDl7Jw4V7AeiAtKioOb29PF0em1LVumBRE5DNjzIvAAhG55t64\nLBp5TanU9s6BZU8CBu75EJq85OqIbpoxhtmzdzB69ArCwqIpVCgfH3/cgSFD7tI7i1SOlV5J4Wfb\n/5kdcU2pm7PvZ1j6GGCg5bvQ7BVXR3TT4uIS6N79J1as+A+ALl2qMXVqd8qXL+LiyJRKX3ojr22x\nvaxtjEmVGGyD59zqyGxKpTiwAAIfsYbTbPEWNH/d1RHdEk9Pd6pUKUrx4t58/nlnHnnkTu3ATuUK\nGQ6yIyJ/G2Map5m23RjTyKmR3YAOspMHHfwVlvSHxHho9ppVSsiFP6B7954jIiKWpk19Abh8OYbo\n6HhKly7g4siUyoJBdkTkQazbUCuLyEK7WYWAsFsPUSngv99gyQNWQmgyNlcmhLi4BD7++E/GjVtH\n+fKF2blzGD4+nhQunJ/ChfO7OjylMiW9NoUtwAXAD5hiNz0C2O7MoNRt4nAg/NYPEuPgrhfh3g9z\nXULYtu0kgwYFsHPnGQDatKlEQoLerKdyr/TaFI4AR4Cg7AtH3TaOLoeAPpAQC41HQatPclVCiIqK\n4+231/LppxtJTDRUrlyU6dN70K5dFVeHptQtSa/66A9jTCsRuQTYNzwIYIwxxZ0encqbjgXB4l6Q\nEAMNnoXWE3JVQjDG0LHjD2zYcBw3N2H06OaMG9eGAgXyuTo0pW5ZetVHSUNulsyOQNRt4vga+LUn\nxEdD/Weg3eRclRAARISRI5ty8WIUs2b1pFkzP1eHpFSWuWGHeHZPMZcH3I0xCUAL4BlAb6dQmXdi\nHSzqDvFRUG8wtP/SGiwnFwgMPMjkyZuT3/frV4cdO57RhKDyHEe+kb9iDcVZFfgGqA7McWpUKu8J\n/RMWdoX4q1D3Seg4LVckhPPnr/LYY4vo1m0Oo0evYO/ec4BVWvD0dHdxdEplPUf6Pko0xsSJSB9g\nsjFmkojo3UfKcSc3wcIuEHcFaj8KHWfk+IRgjOGXX3YzYsRSzp27ipeXB++914bq1Uu4OjSlnMqR\npBAvIv2Bx4Betmnak5dyzOmtsKATxEZArYeg82xwy9lX2KGhl3n22UACAvYD0Lp1JaZP70G1anpv\nhcr7HEkKg4BnsbrOPiwilYGfnBuWyhPObIP5HSH2MtToD12+y/EJAWDUqGUEBOyncOH8fPJJB556\nqrF2YKduG44Mx7lLREYC1USkFnDIGPO+80NTudrZHTC/A8SEQfU+0PVHcHPkGsQ1jDHJfRN9+mlH\n3N3d+Oyzjvj5FXZxZEplrwwrdkXkXuAQMBOYBRwQkZbODkzlYud2wrz2EH0Jqt4P3X4C95xZ45iQ\nkMiECRvp1m0OiYnW4ziVKhXl55/7aUJQtyVHWvsmAF2NMS2NMXcD3YDPHdm4iHQWkf0ickhEbtgP\nsoj0FREjIhl21qRyuPO7YF47iL4AVbpB95/BPWc+1LV791latpzF6NErWLr0EEFBh10dklIu50hS\nyGeM2ZP0xhizF8jwWy4i7lh9JnUB6gAPiUid6yxXCBgFbE47T+UyF/ZaCSHqPFTqDD3mg0fO6xAu\nNjaBceP+oFGjqWzeHIqvbyF+++0hOnas6urQlHI5Ryp5/xaRr4EfbO8fwbEO8ZpitT8cBhCRucD9\nwJ40y70LfAS87FDEKme6uB/mtYWrZ6FiB+i5EDy8XB3VNbZuDWXQoAB27ToLwDPP3MVHH7WnSJGc\nF6tSruBISWEocBgYY/t3GOup5oz4AiF270/YpiUTkcZAeWPM7+ltSESGiEiwiASfO3fOgV2rbHXp\nIPzSBq6chgpt4f5fwdPb1VFd1+rVR9i16yxVqxZjzZon+Prr7poQlLKTbklBRO4EqgKLjDEfZ+WO\nRcQNGA88mdGyxphpwDSwBtnJyjjULQo7DL+0hSunwK8V9AoATx9XR5XKhQtXKVHCiunFF+/G09Od\noUP98fHJmY3fSrnSDUsKIvI/rC4uHgFWisigTG47FKvfpCR+tmlJCgH1gLUichRoDgRoY3MuEn7U\nKiFEngDfe6D3EvDMOd1ihYdHM3ToEmrW/IIzZyIB8PBwY/ToFpoQlLqB9KqPHgHqG2P6A02AYZnc\n9laguohUFpF8WKO4BSTNNMaEG2NKGmMqGWMqAZuAnsYYHWszN7h83EoIEcehXAvoEwj5Cro6qmRL\nlhygbt0vmTp1G5cvx/DnnyEZr6SUSrf6KMYYcwXAGHPOVt3jMGNMvIgMB5YD7sAsY8xuERkHBBtj\nAtLfgsqxIk5YCeHyUSjXDPoug3yFXB0VAOfOXWHUqGX89NMuAJo182XmzJ7UrVvaxZEplTuklxSq\n2I3NLEBV+7GajTF9Mtq4MSYQCEwz7c0bLNs6w2iV60WetBJC+GEo4w99lkH+nPGQ1++/H+CJJ37l\nwoUofHw8ef/9towY0RR395zd+Z5SOUl6SaFvmvdfODMQlQtEnrISQtghKN0I+q0Ar6KujipZiRI+\nXLwYRbt2lZk2rQdVqhRzdUhK5TrpjdG8KjsDUTnclTPWg2mXDkCpBtBvJXi59kc3MdHwxx9HadOm\nMgDNm/vx11+DadbMN7kfI6VU5mi5WmXs6jkrIVzcCyXrQb8g8HbtuAKHDl2kXbvvaNv2O5YtO5Q8\nvXlzP00ISt2CnNttpcoZrp63EsKF3VCiDvRfBT6uG7Y7Pj6RiRM38cYba4iOjqdUKR/i4hJcFo9S\neY3DSUFE8htjYpwZjMphoi5a3V+f/xeK1bQlBNfdxbNz5xkGDw4gOPgkAI8+Wp+JEzslP5imlLp1\nGSYFEWmK1W12EaCCiDQAnjLGjHB2cMqFosNgQUc4twOKVYcHVkOBsi4L57ff9tOnzy/ExydSvnxh\nvv66O127VndZPErlVY6UFCYB3bGebsYY84+ItHFqVMq1YsKtITTPbIOiVaH/Gih4h0tDuu++ipQt\nW5CePWvw4YftKVw45/W+qlRe4EhScDPGHEvTeKeVuHlVzGVY0BlOb4Eila2EUMg34/Wy2JUrsUyY\nsIkXX2yBt7cnRYp4sXv3s5oMlHIyR5JCiK0KydjGSBgBHHBuWMolYiNhYVc4tQkKV4QH1kDh8hmv\nl8VWrTrM00//xpEjYURExPDRRx0ANCEolQ0cSQrDsKqQKgBngCAy3w+SyunirsCibnDyTyhUHvqv\nthJDNgoLi+bll1cwY4Y1XEeDBmV44IG62RqDUre7DJOCMeYsVmd2Kq+KuwqLesCJdVDQ10oIRatk\nawiLF+9j2LDfOXUqknz53HnrrVa8/LLVzbVSKvs4cvfRdOCaMQyMMUOcEpHKXnFR8Ov9ELIGCpSz\nEkKxatkawoYNx+nV62cAWrTwY+bMntSuXSpbY1BKWRypPgqye+0F9Cb1iGoqt4qPhoDecDwIfMpY\nCaF4jWwPo2XL8jz0UD2aN/fjueeaaAd2SrmQI9VHP9u/F5HvgQ1Oi0hlj/gYCOgLR5eDdynrwbQS\ntbJl1yEh4YwYsZT3329L3bqlERHmzEnb/6JSyhVuppuLykCZrA5EZaOEWPitPxwJBK8SVkIo6fwG\n3cREw9SpwYwZE0RkZCwxMQksXfqI0/erlHKcI20Kl0hpU3ADLgKvODMo5UQJcbBkABz+DbyKWwmh\n1J1O3+2BAxd46qkA1q8/DkCfPrWZMqWr0/erlMqcdJOCWE+sNSBlbOVEY8w1jc4ql0iMh8CH4dAi\nyF/U6v66dAOn7jI+PpHx4zfy1ltriY6Op0yZAkyZ0pW+fes4db9KqZuTblIwxhgRCTTG1MuugJST\nJMZD4GNwYD7kL2IlhDKNnb7b0NDLvPPOH0RHx/PEEw0YP74TxYt7O32/Sqmb40ibwg4RaWSM2e70\naJRzJCbAsidh/1xrLOW+y6Gsv9N2FxMTj6enO25uQsWKRZkypSvlyhWkU6fsvdVVKZV5N7z3T0SS\nEkYjYKuI7BeRv0Vku4j8nT3hqVuWmADLB8HeH8GzoDWmcrlmTtvdxo0hNGo0lRkzUj4iTz7ZUBOC\nUrlEeiWFLUBjoGc2xaKymkmElUNgz3fgWQD6LAXfu52yq8jIWF5/fTWTJm3GGJg5cztPP91YR0FT\nKpdJLykIgDHmv2yKRWUlkwgrh8KuWeDhDb1/B797nLKrlSv/Y8iQJRw9Goa7uzB2bEveeKOVJgSl\ncqH0kkIpERl9o5nGmPFOiEdlBWNg1XD4dzp4eEHvJVC+VZbvJjIylpEjl/LNNzsAaNSoLLNm3U/D\nhq4bjEcpdWvSSwruQEFsJQaVSxgDa0bBP1+Be364fzFUaOuUXeXP787ff58if3533n67NS++2EI7\nsFMql0svKZwyxozLtkjUrTMG1o6G7ZPBPR/cvwgqdczSXZw+HYm7u1CqVAE8Pd354Yc+eHq6UbNm\nySzdj1LKNdLreUxLCLmJMbBuLPw9Edw8occCqNwlCzdv+PbbHdSpM4URI5YmT69Xr7QmBKXykPRK\nCu2yLQp1a4yBDa9B8Cfg5gE95kHV7lm2+WPHwnjmmSUsX27dcxAWFk10dDxeXjfTdZZSKie74bfa\nGHMxOwNRt+Cvt2HLhyDu0P1nqHZ/lmw2MdHw5ZdbeeWVIK5ciaNYMS8mTuzMY4/V1zuLlMqj9FIv\nt9s4DjaNsxJCt5+gep8s2WxcXALt2n2X3IFd//51mDy5C2XKFMyS7SulcianjmYiIp1tT0IfEpFr\nelYVkdEiskdEdorIKhHJ3kGBc7vNH8Bfb4G4QZfvoWb/LNu0p6c7DRqUoWzZgixc+AC//NJfE4JS\ntwFxVqenIuIOHAA6ACeArcBDxpg9dsu0ATYbY66KyDCgtTHmwfS26+/vb4KDg50Sc66y5WNYPxYQ\n6PId1Hn0lje5ffsprl6No2XLCoD1HEJcXALFimkHdkrldiKyzRiTYadnziwpNAUOGWMOG2NigblA\nqspuY8waY8xV29tNgJ8T48k7gsenJITO39xyQoiOjufVV4No0mQ6jz66iMjIWAAKFsynCUGp24wz\n2xR8ST2W8wkgvZ7YBgNLrzdDRIYAQwAqVKiQVfHlTn9Pgj9etF53nA51n7ilzW3YcJzBgwM4cOAC\nItCrV020DVmp21eOaGgWkUcBf+C6fTEYY6YB08CqPsrG0HKW7VOsp5UB2n8Ndw6+6U1FRMTw6qur\nmDJlKwC1a5dk5syetGhRPisiVUrlUs5MCqGA/S+MHykjuCUTkfbAa0ArY0yME+PJ3f6ZCquHW6/b\nfgENnrnpTRlj6NjxBzZtOoGHhxuvvnoPr712L/nz54hrBKWUCzmzTWErUF1EKotIPmAAEGC/gIg0\nAqYCPY0xZ50YS+7270wIGmq9bjMRGj13S5sTEcaMuZu77ipHcPDTjBvXRhOCUgpwYknBGBMvIsOB\n5Vid680yxuwWkXFAsDEmAPgEq9O9ebaHoY4bY3T8Bnu7v4UVT1uvW30GjUdlehPGGBYs2MvRo2G8\n9JI1nkLv3rXp2bMm7u5OvStZKZXLOPXy0BgTCASmmfam3ev2ztx/rrfnB1g2EDBw70fgf8OezG/o\n1KkInnsukEWL9uHuLnTrVp3atUsBaEJQSl1D6wxyqn1zYdkTgIF73oemYzK1ujGG2bN3MHr0CsLC\noilUKB8ff9xBO69TSqVLk0JOtH8eBD5qjZ529zvQ7H+ZWv3IkUsMGbKEoKDDAHTtWp2vv+5G+fJF\nnBGtUioP0aSQ0xxcCL8/BCYBmr8BLd7MeJ00xowJIijoMCVKePP55515+OE7tQM7pZRDNCnkJIcW\nw5IHrYTQ9FWrlOCgxESDm5v1wz9+fEcKFszHRx+1p3TpAs6KVimVB2lLY07x3xL4rT8kxoP/S1Y7\nggNX93FxCbz33jrat/+OhIREAMqXL8I339yvCUEplWlaUsgJjiyD3/pCYhw0fh7u+9ihhLBt20kG\nDQpg584zAKxde5R27ao4O1qlVB6mJQVXO7oSFveChFhoOBxaj88wIURFxTF27EqaNp3Bzp1nqFKl\nGKtWPa4JQSl1y7Sk4ErHV8PinpAQAw2GQdtJGSaE9euPMXhwAAcPXsTNTRg9ujnvvtsWHx/PbApa\nKZWXaVJwlZA/YFEPiI+GO5+Gdl84VGW0ZUsoBw9epG7dUsyc2ZNmzbS3caVU1tGk4AonNsCibhB/\nFeoOhA5fW6On3cCpUxGUK1cIgOefb46PjyeDBzcmXz737IpYKXWb0DaF7HZyIyzsAnFXoM7j1pgI\nN0gI589f5dFHF1K79hROnowArK4phg1roglBKeUUmhSy06nNsKATxEVCrYeh0yxwu/bH3RjDzz/v\nok6dKfz447/ExiYQHHzSBQErpW43Wn2UXU4HWwkhNgJqPghdvr1uQjh5MoJhw34nIGA/AK1bV2L6\n9B5Uq1Y8uyNWSt2GNClkhzN/w/wOEBMONfpB1x/A7dpTv2jRXgYOXEx4eAyFC+fn0087MHhw4+Qn\nlZVSytk0KTjb2X9sCSEMqvWGrnOumxAA/PwKExERS48eNfjqq274+hbO5mCVUrc7TQrOdO5fmNcO\noi9ClR7QfS64pzxPkJCQyLJlh+jWrQYATZr4sm3bEBo0KKMd2CmlXEIbmp3lwh5bQrgAlbtCj3ng\nni959q5dZ7n77ll07/4TS5YcSJ7esGFZTQhKKZfRkoIzXNgHv7SFqHNQsSP0XAAe+QGIjU3gww/X\n8/7764mLS8TXtxD58+vtpUqpnEGTQla7dBDmtYWrZ6BCO7j/V/DwAmDr1lAGDQpg166zAAwdehcf\nfdSBwoXzuzJipZRKpkkhK4X9B7+0gSunoHxr6BUAnt6AdWdRv37zSEw0VKtWnBkzetCqVSWXhquU\nUmlpUsgq4UeshBAZCr73Qu8l4OmTPLtduypUqFCE/v3r8PbbrbUDO6VUjqRJIStcPmYlhIgQuKMl\n9Pmd8KvufPTRKl5//T58fDwpXDg/u3c/q8lAKZWjaVK4VZdDrIRw+RiUaw59Avlt+UmGDv2dkycj\niI1N4NNPOwJoQlBK5XiaFG5FRCjMa2NVHZVtwrn7FjJq4Ep++mkXAM2b+zFoUCMXB6mUUo7TpHCz\nIk9ZCSHsP0zpu/gpbhIjG37PhQtR+Ph48sEHbRk+vCnu7vooiFIq99CkcDOunLZuO710EEo1ZH3Z\nb3ik40IA2rWrzLRpPahSpZiLg1RKqczTpJBZV89aTypf3Acl74R+K7nXuwQDBx7mnnsqMHBgQ30i\nWSmVa2lSyIyr52Feew7uO82zvw3js1kjqO9TEgFmzbrf1dEppdQt06TgqKiLxP/cgYkLC/HG8meJ\njvPglXf+JjCwtqsjUzlUXFwcJ06cIDo62tWhqNuIl5cXfn5+eHre3N2OTk0KItIZ+BxwB2YYY/4v\nzfz8wHfAXcAF4EFjzFFnxnRToi+xc3xfBn/dhOATvgA8/ngDxo/v6OLAVE524sQJChUqRKVKlbRK\nUWULYwwXLlzgxIkTVK5c+aa24bRbY0TEHZgCdAHqAA+JSJ00iw0GLhljqgETgI+cFc/Nigk/z1sP\nDeeuN+8l+IQv5f0KEBj4MN9+24sSJXwy3oC6bUVHR1OiRAlNCCrbiAglSpS4pdKpM++XbAocMsYc\nNsbEAnOBtBXv9wPf2l7PB9pJTvoGxUZy5tt+jF9akfhEd557uja794ygS5fqro5M5RI56eOsbg+3\n+plzZvWRLxBi9/4E0OxGyxhj4kUkHCgBnLdfSESGAEMAKlSo4Kx4r+XhTYWaVZn22Cb8+v4f93Zu\nmn37VkopF8gVT1YZY6YZY/yNMf6lSpXKvh27uUPH6Tw08SdNCCpXcnd3p2HDhtSrV48ePXoQFhaW\nPG/37t20bduWmjVrUr16dd59912MMcnzly5dir+/P3Xq1KFRo0a8+OKLrjiEdG3fvp3Bgwe7Oox0\nffjhh1SrVo2aNWuyfPny6y5jjOG1116jRo0a1K5dm0mTJqWav3XrVjw8PJg/fz4A586do3Pnzk6J\n15lJIRQob/fezzbtusuIiAdQBKvBOecQNyhQxtVRKHVTvL292bFjB7t27aJ48eJMmTIFgKioKHr2\n7Mkrr7zC/v37+eeff/jrr7/48ssvAdi1axfDhw/nhx9+YM+ePQQHB1OtWrUsjS0+Pv6Wt/HBBx8w\ncuTIbN1nZuzZs4e5c+eye/duli1bxrPPPktCQsI1y82ePZuQkBD27dvH3r17GTBgQPK8hIQExo4d\nS8eOKTe2lCpVinLlyvHnn39meczOrD7aClQXkcpYP/4DgIfTLBMAPAFsBPoBq439pYpSecVnTmpb\neNHxr0uLFi3YuXMnAHPmzKFly5bJPzQ+Pj588cUXtG7dmueee46PP/6Y1157jVq1agFWiWPYsGHX\nbDMyMpIRI0YQHByMiPDWW2/Rt29fChYsSGRkJADz589nyZIlzJ49myeffBIvLy+2b99Oy5YtWbhw\nITt27KBo0aIAVK9enQ0bNuDm5sbQoUM5fvw4ABMnTqRly5ap9h0REcHOnTtp0KABAFu2bGHUqFFE\nR0fj7e3NN998Q82aNZk9ezYLFy4kMjKShIQE/vjjDz755BN++eUXYmJi6N27N++88w4AvXr1IiQk\nhOjoaEaNGsWQIUMcPr/Xs3jxYgYMGED+/PmpXLky1apVY8uWLbRo0SLVcl999RVz5szBzc26Ti9d\nunTyvMmTJ9O3b1+2bt2aap1evXrx448/XnNebpXTkoKtjWA4sBzrltRZxpjdIjIOCDbGBAAzge9F\n5BBwEStxKKWyWEJCAqtWrUquatm9ezd33XVXqmWqVq1KZGQkly9fZteuXQ5VF7377rsUKVKEf//9\nF4BLly5luM6JEyf466+/cHd3JyEhgUWLFjFw4EA2b95MxYoVKVOmDA8//DAvvPAC99xzD8ePH6dT\np07s3bs31XaCg4OpV69e8vtatWqxfv16PDw8CAoK4n//+x8LFiwA4O+//2bnzp0UL16cFStWcPDg\nQbZs2YIxhp49e7Ju3Truu+8+Zs2aRfHixYmKiqJJkyb07duXEiVKpNrvCy+8wJo1a645rgEDBvDK\nK6+kmhYaGkrz5s2T3/v5+REamrbCBP777z9+/vlnFi1aRKlSpZg0aRLVq1cnNDSURYsWsWbNmmuS\ngr+/P6+//nqG5zuznPqcgjEmEAhMM+1Nu9fRQH9nxqBUjpCJK/qsFBUVRcOGDQkNDaV27dp06NAh\nS7cfFBTE3Llzk98XK5Zxn1/9+/fH3d0al/zBBx9k3LhxDBw4kLlz5/Lggw8mb3fPnj3J61y+fJnI\nyEgKFiyYPO3UqVPYtzGGh4fzxBNPcPDgQUSEuLi45HkdOnSgePHiAKxYsYIVK1bQqJHVg3FkZCQH\nDx7kvvvuY9KkSSxatAiAkJAQDh48eE1SmDBhgmMnJxNiYmLw8vIiODiYhQsXMmjQINavX8/zzz/P\nRx99lFyCsFe6dGlOnjyZ5bHoE81K5WFJbQpXr16lU6dOTJkyhZEjR1KnTh3WrVuXatnDhw9TsGBB\nChcuTN26ddm2bVty1Uxm2d8Wmfae+QIFCiS/btGiBYcOHeLcuXP8+uuvyVe+iYmJbNq0CS8vr3SP\nzX7bb7zxBm3atGHRokUcPXqU1q1bX3efxhheffVVnnnmmVTbW7t2LUFBQWzcuBEfHx9at2593fv9\nM1NS8PX1JSQk5SbMEydO4Ovre826fn5+9OnTB4DevXszcOBAwCoNJbUvnD9/nsDAQDw8POjVq1dy\nNVlWyxV3Hymlbo2Pjw+TJk3is88+Iz4+nkceeYQNGzYQFBQEWCWKkSNHMmbMGABefvllPvjgAw4c\nOABYP9Jff/31Ndvt0KFDcuM1pFQflSlThr1795KYmJh85X09IkLv3r0ZPXo0tWvXTr4q79ixI5Mn\nT05ebseOHdesW7t2bQ4dOpT8Pjw8PPkHd/bs2TfcZ6dOnZg1a1Zym0doaChnz54lPDycYsWK4ePj\nw759+9i0adN1158wYQI7duy45l/ahADQs2dP5s6dS0xMDEeOHOHgwYM0bXrtnYy9evVKTjR//PEH\nNWrUAODIkSMcPXqUo0eP0q9fP/6/vfsPkrqu4zj+fKXAYZKlaINhoqPCHXcHZ4cDOIMZxlxganVz\nJypKI5UUNUrmcCNNVvxBY6aREBo6aCqakh1jljl2Rjmgnin4A0U6ya6cvCG6uVGswHd/fD73ZT0X\n9nt3e7vs3fsxszO73/1uLysAAAlASURBVP1+9/t+7+7tez+fz97ns2rVKi644AIAtm/f/p7us3zx\nouDcEFFTU0N1dTXr1q1j5MiRNDc3s2zZMsaPH09VVRVTpkxh0aJFAFRXV3PTTTcxd+5cysvLqays\npK2t7X2PuXTpUnbv3k1lZSWTJk1KPtiWL1/Oueeey/Tp0xkzZsxB42psbOSuu+5Kuo4AVqxYQWtr\nK9XV1VRUVGQtSBMmTKCzs5Ouri4ArrnmGpqamqipqTnor4xmzZrFRRddxLRp06iqqqK+vp6uri7q\n6urYu3cv5eXlLFmy5D1jAX01ceJEGhoaqKiooK6ujpUrVyZdZ7Nnz066f5YsWcL69eupqqqiqamJ\nNWvW5HzslpYW5syZ0+8Ye1Kp/dintrbWWltbix2Gczlt27aN8nKfMHEg3XjjjYwaNYoFCxYUO5SC\nmzFjBs3NzVnHcbK99yQ9Y2a1uR7XWwrOuZK1cOFCRowYUewwCq6jo4PFixenGtjvLS8KzrmSVVZW\nxrx584odRsEde+yxydhCvnlRcG4AlVr3rCt9/X3PeVFwboCUlZWxa9cuLwyuYLrXUzjYT3lz8f9T\ncG6AjB07lvb2djo6OoodihtCulde6ysvCs4NkGHDhvV59SvnisW7j5xzziW8KDjnnEt4UXDOOZco\nuf9oltQB/LXApx1NjyVCB6mhkicMnVw9z8GlP3meaGY5l64suaJQDJJa0/x7eKkbKnnC0MnV8xxc\nCpGndx8555xLeFFwzjmX8KKQzq3FDqBAhkqeMHRy9TwHlwHP08cUnHPOJbyl4JxzLuFFwTnnXMKL\nQgZJdZJekbRD0vsWXJU0QtJ98f4nJY0rfJT9lyLPxZJekrRV0mOSTixGnP2VK8+M/b4gySSV7E8a\n0+QqqSG+ri9KuqfQMeZDivfuxyW1SHo2vn9nFyPO/pJ0u6Q3Jb1wgPslaUV8HrZKOj1vJzczv4Rx\nlcOAvwAnA8OBLUBFj32+CqyO1y8E7it23AOU59nAEfH6wsGaZ9xvFLAR2AzUFjvuAXxNTwWeBT4S\nbx9X7LgHKM9bgYXxegWws9hx9zHXGcDpwAsHuH828BtAwFTgyXyd21sK+50B7DCzNjP7L3AvcH6P\nfc4H7ojXHwBmSlIBY8yHnHmaWYuZvR1vbgb6Pg9v8aR5PQG+D/wAeKeQweVZmly/BKw0s90AZvZm\ngWPMhzR5GvCheP0o4B8FjC9vzGwj8K+D7HI+cKcFm4EPSxqTj3N7UdjvY8DfMm63x21Z9zGzvUAn\ncExBosufNHlmupzwjaTU5MwzNrlPMLNfFzKwAZDmNT0NOE3SE5I2S6orWHT5kybP64BLJLUDDwNf\nL0xoBdfbv+PUfD0Fd0CSLgFqgbOKHUu+SfoA8CNgfpFDKZTDCV1InyS0/DZKqjKzfxc1qvybC6w1\nsxskTQN+LqnSzN4tdmClwlsK+/0dOCHj9ti4Les+kg4nNE93FSS6/EmTJ5LOAa4FzjOz/xQotnzK\nlecooBJ4XNJOQr/shhIdbE7zmrYDG8zsf2b2GrCdUCRKSZo8Lwd+AWBmm4AywiRyg02qv+O+8KKw\n39PAqZJOkjScMJC8occ+G4DL4vV64PcWR31KSM48JdUAtxAKQin2PUOOPM2s08xGm9k4MxtHGDs5\nz8xaixNuv6R57/6K0EpA0mhCd1JbIYPMgzR5vg7MBJBUTigKg3E91A3ApfFXSFOBTjN7Ix8P7N1H\nkZntlbQIeITwK4fbzexFSd8DWs1sA3AboTm6gzAIdGHxIu6blHleDxwJ3B/H0V83s/OKFnQfpMxz\nUEiZ6yPALEkvAfuAb5lZSbVyU+b5TeBnkq4iDDrPL8EvbkhaRyjio+P4yHeAYQBmtpowXjIb2AG8\nDXwxb+cuwefLOefcAPHuI+eccwkvCs455xJeFJxzziW8KDjnnEt4UXDOOZfwouAOOZL2SXou4zLu\nIPuOO9BMkr085+Nx9s0tcSqI8X14jCskXRqvz5d0fMZ9ayRV5DnOpyVNTnHMlZKO6O+53dDgRcEd\nivaY2eSMy84CnfdiM5tEmPTw+t4ebGarzezOeHM+cHzGfQvM7KW8RLk/zlWki/NKwIuCS8WLgisJ\nsUXwR0l/jpfpWfaZKOmp2LrYKunUuP2SjO23SDosx+k2AqfEY2fGufmfj3Pcj4jbl2v/mhM/jNuu\nk3S1pHrCnFF3x3OOjN/wa2NrIvkgjy2Km/sY5yYyJkGT9FNJrQrrJXw3bvsGoTi1SGqJ22ZJ2hSf\nx/slHZnjPG4I8aLgDkUjM7qOHozb3gQ+bWanA43AiizHXQH82MwmEz6U2+NUB43AmXH7PuDiHOf/\nLPC8pDJgLdBoZlWEGQAWSjoG+Bww0cyqgWWZB5vZA0Ar4Rv9ZDPbk3H3+nhst0bg3j7GWUeYvqLb\ntWZWC1QDZ0mqNrMVhOmjzzazs+MUF0uBc+Jz2QosznEeN4T4NBfuULQnfjBmGgbcHPvQ9xHm7ulp\nE3CtpLHAL83sVUkzgU8AT8cpO0YSCkw2d0vaA+wkTLk8HnjNzLbH++8AvgbcTFh/4TZJDwEPpU3M\nzDoktcX5al4FJgBPxMftTZzDCVORZD5PDZK+TPi7HkNYZGZrj2Onxu1PxPMMJzxvzgFeFFzpuAr4\nJzCJ0MJ936I4ZnaPpCeBOcDDkr5CWJnqDjNrSnGOizMnxJN0dLad4hw8ZxAmXqsHFgGf6kUu9wIN\nwMvAg2ZmCp/QqeMEniGMJ/wE+Lykk4CrgSlmtlvSWsJkcD0JeNTM5vYiXjeEePeRKxVHAW/EefHn\nESZEew9JJwNtscukmdCN8hhQL+m4uM/RSr/m9CvAOEmnxNvzgD/EPvijzOxhQrGalOXYLsL03Nk8\nSFg5ay6hQNDbOOMkb98GpkqaQFht7C2gU9JHgc8cIJbNwJndOUn6oKRsrS43RHlRcKViFXCZpC2E\nLpe3suzTALwg6TnCWgl3xl/8LAV+J2kr8CihayUnM3uHMPvk/ZKeB94FVhM+YB+Kj/cnsvfJrwVW\ndw8093jc3cA24EQzeypu63WccaziBsKMp1sIazC/DNxD6JLqdivwW0ktZtZB+GXUunieTYTn0znA\nZ0l1zjmXwVsKzjnnEl4UnHPOJbwoOOecS3hRcM45l/Ci4JxzLuFFwTnnXMKLgnPOucT/AazisNm6\nW9dpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "results are RMSE, accuracy, ROC, loss function\n",
            "0.7033355181304509 0.5053191489361702 0.6443820224719101 0.49468085106382975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MwYMDPWe9OBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Subtask5"
      ]
    },
    {
      "metadata": {
        "id": "fhgJM6f96Tgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def precision_score(y_true, y_pred):\n",
        "    '''\n",
        "    The y_true is the label of dev data and the y_pred is the prediciton of the model\n",
        "    '''\n",
        "    return ((y_true==1)*(y_pred==1)).sum()/(y_pred==1).sum()\n",
        "\n",
        "def recall_score(y_true, y_pred):\n",
        "    '''\n",
        "    The y_true is the label of dev data and the y_pred is the prediciton of the model\n",
        "    '''\n",
        "    return ((y_true==1)*(y_pred==1)).sum()/(y_true==1).sum()\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    '''\n",
        "    The y_true is the label of dev data and the y_pred is the prediciton of the model\n",
        "    '''\n",
        "    num = 2 * precision_score(y_true, y_pred)*recall_score(y_true, y_pred)\n",
        "    deno = (precision_score(y_true, y_pred)+recall_score(y_true, y_pred))\n",
        "    return num/deno"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Ddgui-N9Oi4",
        "colab_type": "code",
        "outputId": "aea2e5a4-8b1d-495f-99a8-b0da20f069a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "dev_y = np.array(np.squeeze(dev_y).tolist())\n",
        "predict_y = np.array(predict_y)\n",
        "\n",
        "print(precision_score(dev_y, predict_y))\n",
        "print(recall_score(dev_y, predict_y))\n",
        "print(f1_score(dev_y, predict_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08080808080808081\n",
            "0.8\n",
            "0.1467889908256881\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}