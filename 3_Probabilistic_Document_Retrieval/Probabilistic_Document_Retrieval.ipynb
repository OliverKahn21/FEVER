{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Subtask3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HbRJlvnIqL0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Subtask3"
      ]
    },
    {
      "metadata": {
        "id": "gAb1GVURqMWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from fever_io import load_dataset_json\n",
        "from math import *\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkqbTKVdcpPZ",
        "colab_type": "code",
        "outputId": "5ccd3d30-3808-4423-ba79-beeb0a3d5344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cMC82x483rBG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = '/content/gdrive/My Drive/IRDM_CHFX2/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0u9SPGyqP_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def n_dict_subtask3(filepath):\n",
        "    '''\n",
        "    The input is the path of wiki-pages.\n",
        "    The output is the dictionary which the key is the term and the value is the frequency of the term.\n",
        "    The output is 98 MB so it is not including in the file.\n",
        "    '''\n",
        "    n_dict = {}\n",
        "    files = os.listdir(filepath)\n",
        "    for i in files:\n",
        "        with open(os.path.join(filepath, i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                text = eval(line)['text'] ## extract data from the field of 'text'.\n",
        "                words = text.split(' ')\n",
        "                for w in words:\n",
        "                    w = w.replace(\"-LRB-\",\"\").replace(\"-RRB-\",\"\").replace(\"-LSB-\",\"\").replace(\"-RSB-\",\"\").replace(\"--\",\"\")\n",
        "                    w = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", w) ## replace the noisy with space. \n",
        "                    if not w in n_dict:\n",
        "                        n_dict[w] = 1\n",
        "                    else:\n",
        "                        n_dict[w] += 1 ## count the frequencies of every term.\n",
        "    np.save(PATH + \"n_dict_Subtask3.npy\",n_dict)\n",
        "    print ('save complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrEbzZOqqUth",
        "colab_type": "code",
        "outputId": "55bd4b07-255f-46cc-cfe4-913f8166fbeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "n_dict_subtask3(PATH + 'data/wiki-pages/wiki-pages/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "save complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aTOxkohAqXln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask3_0(claim_id):\n",
        "    '''\n",
        "    The input is the claim id.\n",
        "    The output is the claim, the 5 most similar documents and the query-likelihood unigram language model value.\n",
        "    The out putis save in the 'Q3_unigram.csv'.\n",
        "    In the query likelihood unigram language model, I do some smoothing to improve the result.\n",
        "    For the terms in claim which do not appear in the document, the probability is not 0 but the probability it appear in the wiki-pages or p = 0.01 for the term even not appear in wiki-pages.\n",
        "    '''\n",
        "    alpha = 0.5\n",
        "\n",
        "    train_data = load_dataset_json(PATH + 'data/train.jsonl', instance_num=20)\n",
        "\n",
        "    claim = None\n",
        "    for d in train_data:\n",
        "        if d['id'] == claim_id:\n",
        "            claim = d['claim'][:-1]\n",
        "            claim = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "            claim = claim.split(' ')\n",
        "            break\n",
        "    print(d['id'])\n",
        "    print(d['claim'])\n",
        "\n",
        "    data = np.load(PATH + 'n_dict_Subtask3.npy', allow_pickle=True).item()\n",
        "    C = sum(data.values())\n",
        "    f = []\n",
        "\n",
        "    f = []\n",
        "    files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "    for i in files:\n",
        "        with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                text = eval(line)['text']\n",
        "                tmp = 0\n",
        "                for w in claim:\n",
        "                    if w in text:\n",
        "                        p = text.count(w) / len(text) ## calculate the probability for the terms appear in the document.\n",
        "                    else:\n",
        "                        if w in data:\n",
        "                            p = alpha * data[w] / C ## calculate the probability for the terms not appear in the document by using the probability it appear in the wiki-pages.\n",
        "                        else:\n",
        "                            p = 0.001 ## the probability of the terms do not appear in wiki-pages is 0.001.\n",
        "                    tmp += log(p) ## calculate the log(p) of the claim.\n",
        "                f.append((eval(line)['id'], tmp))\n",
        "    f.sort(key=lambda x:x[1], reverse=True)\n",
        "    return f[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1oiajqEjqZxP",
        "colab_type": "code",
        "outputId": "bbf07cc4-6854-42e3-8b83-676db49c3966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "index_list = [\n",
        "75397,\n",
        "150448,\n",
        "214861,\n",
        "156709,\n",
        "129629,\n",
        "33078,\n",
        "6744,\n",
        "226034,\n",
        "40190,\n",
        "76253]\n",
        "\n",
        "for index in index_list:\n",
        "    print(Subtask3_0(index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75397\n",
            "Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "[('New_Amsterdam_-LRB-TV_series-RRB-', -59.87846610283076), ('Ved_verdens_ende', -59.99347182222764), ('Nikolaj_Coster-Waldau', -60.228888352654025), ('A_Thousand_Times_Good_Night', -60.996370163158), ('The_Other_Woman_-LRB-2014_film-RRB-', -61.42922043408902)]\n",
            "150448\n",
            "Roman Atwood is a content creator.\n",
            "[('Bedside_Press', -35.14365238305695), ('Appticles', -38.396324446678605), ('Only_Much_Louder', -40.41470114501408), ('Roman_Atwood', -40.46609391817583), ('Abominable_Pictures', -40.67484796108127)]\n",
            "214861\n",
            "History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.\n",
            "[('History_of_art', -131.91786544237357), ('Fine_art', -135.19189978689758), ('World_Festival_of_Black_Arts', -135.6596758232308), ('The_arts', -135.7330800444195), ('Tamil_culture', -135.9928999920403)]\n",
            "156709\n",
            "Adrienne Bailon is an accountant.\n",
            "[('Empire_Girls-COLON-_Julissa_and_Adrienne', -32.18530134451106), (\"All_You've_Got\", -33.3729765002758), ('Julissa_Bermudez', -33.584114111476666), ('Adrienne_Bailon', -33.798506476871125), (\"I'm_in_Love_with_a_Church_Girl\", -34.75590418512317)]\n",
            "129629\n",
            "Homeland is an American television spy thriller based on the Israeli television series Prisoners of War.\n",
            "[('Homeland_-LRB-season_6-RRB-', -94.8131685883671), ('Homeland_-LRB-season_2-RRB-', -94.98239649329227), ('Homeland_-LRB-season_3-RRB-', -95.0929154092468), ('List_of_Homeland_episodes', -97.76854905911198), ('Homeland_-LRB-season_4-RRB-', -98.80491239741121)]\n",
            "33078\n",
            "The Boston Celtics play their home games at TD Garden.\n",
            "[('1974–75_Boston_Celtics_season', -61.00710583851291), ('TD_Garden', -64.64290825342935), ('List_of_Boston_Celtics_head_coaches', -65.30471316709068), ('North_Station', -65.76716717544969), (\"2014–15_Providence_Friars_men's_ice_hockey_season\", -65.79155484272317)]\n",
            "6744\n",
            "The Ten Commandments is an epic film.\n",
            "[('Katherine_Orrison', -35.374993557111125), ('The_Nth_Commandment', -36.75090188893664), ('The_King_of_Kings_-LRB-1927_film-RRB-', -37.16821729575907), ('Debra_Paget', -37.312102886807615), ('After_the_Truth', -38.202894007101534)]\n",
            "226034\n",
            "Tetris has sold millions of physical copies.\n",
            "[('Tetris', -51.992538709793266), ('Corum_II-COLON-_Dark_Lord', -52.34067544458707), ('Peggy_Anderson', -52.729016269722194), ('Io_vagabondo', -52.959370537439), ('Eva_Strittmatter', -53.55011797268199)]\n",
            "40190\n",
            "Cyndi Lauper won the Best New Artist award at the 27th Grammy Awards in 1985.\n",
            "[('Cyndi_Lauper', -94.1155177717302), (\"She's_So_Unusual\", -102.17295181777774), ('List_of_awards_and_nominations_received_by_Cyndi_Lauper', -105.79296597429962), ('List_of_Billboard_200_number-one_albums_of_1985', -106.20495452732857), ('And_We_Danced_-LRB-The_Hooters_song-RRB-', -106.3400453997254)]\n",
            "76253\n",
            "There is a movie called The Hunger Games.\n",
            "[('Nina_Jacobson', -46.14105690233556), ('The_Hunger_Games-COLON-_Catching_Fire_–_Original_Motion_Picture_Soundtrack', -46.51399199347493), ('The_Hunger_Games', -47.157105474233475), ('The_Hunger_Games-COLON-_Mockingjay', -48.28261871018408), ('Jo_Blankenburg', -48.412718635263765)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wDywy-Jnqbpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask3_Laplace(claim_id):\n",
        "    '''\n",
        "    The input is the claim id.\n",
        "    The output is the claim, the 5 most similar documents and the Laplace Smoothing query-likelihood unigram language model value.\n",
        "    The output is save in the 'Q3_laplace.csv'.\n",
        "    '''\n",
        "    alpha = 0.5\n",
        "\n",
        "    train_data = load_dataset_json(PATH + 'data/train.jsonl', instance_num=20)\n",
        "\n",
        "    claim = None\n",
        "    for d in train_data:\n",
        "        if d['id'] == claim_id:\n",
        "            claim = d['claim'][:-1]\n",
        "            claim = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "            claim = claim.split(' ')\n",
        "            break\n",
        "    print(d['id'])\n",
        "    print(d['claim'])\n",
        "\n",
        "    data = np.load(PATH + 'n_dict_Subtask3.npy', allow_pickle=True).item()\n",
        "    C = sum(data.values())\n",
        "    f = []\n",
        "\n",
        "    files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "    for i in files:\n",
        "        with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                text = eval(line)['text'].split(' ')\n",
        "                tmp = 0\n",
        "                for w in claim:\n",
        "                    if w in text:\n",
        "                        p = (text.count(w) + 1) / (len(text) + 1) ## calculate the probability for the terms appear in the document.\n",
        "                    else:\n",
        "                        if w in data:\n",
        "                            p = alpha * (data[w] + 1) / (C + len(data)) ## calculate the probability for the terms not appear in the document by using the Laplace Smoothing.\n",
        "                        else:\n",
        "                            p = 0.01 ## the probability of the terms do not appear in wiki-pages is 0.001.\n",
        "                    tmp += log(p) ## calculate the log(p) of the claim.\n",
        "                f.append((eval(line)['id'], tmp))\n",
        "    f.sort(key=lambda x:x[1], reverse=True)\n",
        "    return f[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ccYA0UBqdzz",
        "colab_type": "code",
        "outputId": "ec179c07-dcca-408a-8b77-d52eef5dbfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "index_list = [\n",
        "75397,\n",
        "150448,\n",
        "214861,\n",
        "156709,\n",
        "129629,\n",
        "33078,\n",
        "6744,\n",
        "226034,\n",
        "40190,\n",
        "76253]\n",
        "\n",
        "for index in index_list:\n",
        "    print(Subtask3_Laplace(index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75397\n",
            "Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "[('New_Amsterdam_-LRB-TV_series-RRB-', -50.76973653500242), ('The_Other_Woman_-LRB-2014_film-RRB-', -51.621240726089745), ('Nikolaj_Coster-Waldau', -52.08599794571365), ('Nukaaka_Coster-Waldau', -54.646680568578155), ('Fox_45', -54.832812336588766)]\n",
            "150448\n",
            "Roman Atwood is a content creator.\n",
            "[('Only_Much_Louder', -33.31019819610523), ('Tosyn_Bucknor', -34.57610882268118), ('Stacey_Roy', -34.94560210320524), ('Joel_Spolsky', -35.094524034078326), ('Video_copy_detection', -35.19021271308817)]\n",
            "214861\n",
            "History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.\n",
            "[('History_of_art', -94.18366411935254), ('The_arts', -111.3534968720023), ('Fine_art', -111.50080770914465), ('Narrative', -115.17659264548013), ('World_Festival_of_Black_Arts', -116.47043356077488)]\n",
            "156709\n",
            "Adrienne Bailon is an accountant.\n",
            "[('Empire_Girls-COLON-_Julissa_and_Adrienne', -26.134836710369022), ('Loni_Love', -28.00844423985862), (\"All_You've_Got\", -28.488669603087708), ('Cheetah-licious_Christmas', -28.572345900346967), ('3LW', -28.917863641451127)]\n",
            "129629\n",
            "Homeland is an American television spy thriller based on the Israeli television series Prisoners of War.\n",
            "[('List_of_Homeland_episodes', -70.11164467986818), ('Homeland_-LRB-season_2-RRB-', -71.40303074293563), ('Homeland_-LRB-season_3-RRB-', -71.5928151354106), ('Homeland_-LRB-season_6-RRB-', -71.77986872228789), ('Homeland_-LRB-TV_series-RRB-', -75.22132051699768)]\n",
            "33078\n",
            "The Boston Celtics play their home games at TD Garden.\n",
            "[('1974–75_Boston_Celtics_season', -46.177306025480775), (\"2014–15_Providence_Friars_men's_ice_hockey_season\", -46.826562433873086), ('List_of_Boston_Celtics_head_coaches', -47.89708795092919), ('Boston_Celtics', -48.44630254376237), ('1994–95_Boston_Celtics_season', -50.47145280639036)]\n",
            "6744\n",
            "The Ten Commandments is an epic film.\n",
            "[('Katherine_Orrison', -22.66539295392214), ('Debra_Paget', -25.184074250713827), ('The_Nth_Commandment', -26.476265271136487), ('Fredric_M._Frank', -27.076178667962626), ('The_King_of_Kings_-LRB-1927_film-RRB-', -27.133589982893096)]\n",
            "226034\n",
            "Tetris has sold millions of physical copies.\n",
            "[('Tetris', -39.78166328683801), ('Corum_II-COLON-_Dark_Lord', -40.938424312419635), ('John_C._Maxwell', -42.428865389921036), ('Don_Colbert', -43.22269013823443), ('Do_You_Hear_What_I_Hear?', -43.75006133835966)]\n",
            "40190\n",
            "Cyndi Lauper won the Best New Artist award at the 27th Grammy Awards in 1985.\n",
            "[('Cyndi_Lauper', -69.45851082646676), (\"She's_So_Unusual\", -82.79029675988554), ('And_We_Danced_-LRB-The_Hooters_song-RRB-', -83.72406889797583), ('Miss_Ko', -86.44460427738306), ('India_Martínez', -86.97583688106867)]\n",
            "76253\n",
            "There is a movie called The Hunger Games.\n",
            "[('The_Hunger_Games', -37.6887452141611), ('The_Hunger_Games-COLON-_Catching_Fire_–_Original_Motion_Picture_Soundtrack', -37.88684038349363), ('Jayme_Dee', -39.49295245895816), ('The_Hunger_-LRB-1986_film-RRB-', -39.76858911862272), ('Fictional_universe_of_The_Hunger_Games', -39.97672239212184)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7QhNN6vRqfT0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask3_JM(claim_id):\n",
        "    '''\n",
        "    The input is the claim id.\n",
        "    The output is the claim, the 5 most similar documents and the Jelinek-Mercer Smoothing query-likelihood unigram language model value.\n",
        "    The output is save in the 'Q3_jelinek_mercer.csv'.\n",
        "    '''\n",
        "    alpha = 0.5\n",
        "\n",
        "    train_data = load_dataset_json(PATH + 'data/train.jsonl', instance_num=20)\n",
        "\n",
        "    claim = None\n",
        "    for d in train_data:\n",
        "        if d['id'] == claim_id:\n",
        "            claim = d['claim'][:-1]\n",
        "            claim = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "            claim = claim.split(' ')\n",
        "            break\n",
        "    print(d['id'])\n",
        "    print(d['claim'])\n",
        "\n",
        "    data = np.load(PATH + 'n_dict_Subtask3.npy', allow_pickle=True).item()\n",
        "    C = sum(data.values())\n",
        "    f = []\n",
        "\n",
        "    files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "    for i in files:\n",
        "        with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                text = eval(line)['text'].split(' ')\n",
        "                tmp = 0\n",
        "                for w in claim:\n",
        "                    if w in data:\n",
        "                        p = alpha * text.count(w) / len(text) + (1 - alpha) * data[w] / C ## calculate the probability for the terms appear in the document by using the Jelinek-Mercer Smoothing.\n",
        "                    else:\n",
        "                        p = alpha * text.count(w) / len(text) ## calculate the probability for the terms not appear in the document by using the Jelinek-Mercer Smoothing.\n",
        "                    tmp += log(p) ## calculate the log(p) of the claim.\n",
        "                f.append((eval(line)['id'], tmp))\n",
        "    f.sort(key=lambda x:x[1], reverse=True)\n",
        "    return f[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IexUKZFAqg8O",
        "colab_type": "code",
        "outputId": "8b875ca4-d944-4c72-eb48-27054ed21b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "index_list = [\n",
        "75397,\n",
        "150448,\n",
        "214861,\n",
        "156709,\n",
        "129629,\n",
        "33078,\n",
        "6744,\n",
        "226034,\n",
        "40190,\n",
        "76253]\n",
        "\n",
        "for index in index_list:\n",
        "    print(Subtask3_JM(index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75397\n",
            "Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "[('New_Amsterdam_-LRB-TV_series-RRB-', -54.59930393193907), ('Nikolaj_Coster-Waldau', -55.55275862991747), ('The_Other_Woman_-LRB-2014_film-RRB-', -55.59365030594862), ('Ved_verdens_ende', -57.924043931964306), ('Nukaaka_Coster-Waldau', -57.95257191302444)]\n",
            "150448\n",
            "Roman Atwood is a content creator.\n",
            "[('Only_Much_Louder', -37.872819586379364), ('Joel_Spolsky', -38.757393741621456), ('Tosyn_Bucknor', -39.14533053039745), ('Brett_Atwood', -39.23180145498373), ('Bedside_Press', -39.38852167039723)]\n",
            "214861\n",
            "History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.\n",
            "[('History_of_art', -112.9840675462393), ('The_arts', -124.22444576561661), ('Fine_art', -124.51267874848115), ('World_Festival_of_Black_Arts', -128.11753745058834), ('Narrative', -128.6320557285994)]\n",
            "156709\n",
            "Adrienne Bailon is an accountant.\n",
            "[('Empire_Girls-COLON-_Julissa_and_Adrienne', -30.514783574810984), (\"All_You've_Got\", -31.98459308436578), ('Loni_Love', -32.20235436176452), ('3LW', -32.76197248009946), ('Adrienne_Bailon', -32.84283489965517)]\n",
            "129629\n",
            "Homeland is an American television spy thriller based on the Israeli television series Prisoners of War.\n",
            "[('Homeland_-LRB-season_2-RRB-', -84.13582969928592), ('Homeland_-LRB-season_3-RRB-', -84.30491319808019), ('Homeland_-LRB-season_6-RRB-', -84.47133119861729), ('List_of_Homeland_episodes', -84.7361782660943), ('Homeland_-LRB-season_4-RRB-', -87.66729877383611)]\n",
            "33078\n",
            "The Boston Celtics play their home games at TD Garden.\n",
            "[('1974–75_Boston_Celtics_season', -54.53931072859393), ('List_of_Boston_Celtics_head_coaches', -57.11847518506869), (\"2014–15_Providence_Friars_men's_ice_hockey_season\", -57.63635974091296), ('Boston_Celtics', -58.387291946428945), ('TD_Garden', -58.416994829841755)]\n",
            "6744\n",
            "The Ten Commandments is an epic film.\n",
            "[('Katherine_Orrison', -30.73484563762417), ('The_Nth_Commandment', -32.865988450358955), ('Debra_Paget', -33.06512159895421), ('The_King_of_Kings_-LRB-1927_film-RRB-', -33.630805548007274), ('The_Ten_Commandments_-LRB-1923_film-RRB-', -33.87093579264501)]\n",
            "226034\n",
            "Tetris has sold millions of physical copies.\n",
            "[('Tetris', -44.83208429176088), ('Corum_II-COLON-_Dark_Lord', -46.834719977351156), ('John_C._Maxwell', -48.222420955988305), ('Don_Colbert', -48.63168838237253), ('Io_vagabondo', -48.897604933790596)]\n",
            "40190\n",
            "Cyndi Lauper won the Best New Artist award at the 27th Grammy Awards in 1985.\n",
            "[('Cyndi_Lauper', -81.9520732376527), (\"She's_So_Unusual\", -92.45204755305443), ('And_We_Danced_-LRB-The_Hooters_song-RRB-', -94.85853079857513), ('Summertime-COLON-_Willie_Nelson_Sings_Gershwin', -97.51856643462085), ('List_of_awards_and_nominations_for_the_musical_Kinky_Boots', -97.81355078319885)]\n",
            "76253\n",
            "There is a movie called The Hunger Games.\n",
            "[('The_Hunger_Games', -42.36247581348339), ('The_Hunger_Games-COLON-_Catching_Fire_–_Original_Motion_Picture_Soundtrack', -42.45676075147557), ('Fictional_universe_of_The_Hunger_Games', -44.82791955998704), ('Jayme_Dee', -45.14311661587956), ('The_Hunger_-LRB-1986_film-RRB-', -45.39937421074056)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aHv0i2NUqjD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Subtask3_Dirichlet(claim_id):\n",
        "    '''\n",
        "    The input is the claim id.\n",
        "    The output is the claim, the 5 most similar documents and the Dirichlet Smoothing query-likelihood unigram language model value.\n",
        "    The output is save in the 'Q3_dirichlet.csv'.\n",
        "    '''\n",
        "    train_data = load_dataset_json(PATH + 'data/train.jsonl', instance_num=20)\n",
        "\n",
        "    claim = None\n",
        "    for d in train_data:\n",
        "        if d['id'] == claim_id:\n",
        "            claim = d['claim'][:-1]\n",
        "            claim = re.sub(\"[,.。:_=+*&^%$#@!?()<>/`';|]\", \"\", claim)\n",
        "            claim = claim.split(' ')\n",
        "            break\n",
        "    print(d['id'])\n",
        "    print(d['claim'])\n",
        "\n",
        "    data = np.load(PATH + 'n_dict_Subtask3.npy', allow_pickle=True).item()\n",
        "    C = sum(data.values())\n",
        "    N = 5396106\n",
        "    u = C/N\n",
        "    f = []\n",
        "\n",
        "    files = os.listdir(PATH + 'data/wiki-pages/wiki-pages/')\n",
        "    for i in files:\n",
        "        with open(os.path.join(PATH + 'data/wiki-pages/wiki-pages/', i)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                text = eval(line)['text'].split(' ')\n",
        "                alpha = u / (len(text) + u)\n",
        "                tmp = 0\n",
        "                for w in claim:\n",
        "                    if w in data:\n",
        "                        p = (text.count(w) + u * data[w] / C) / (len(text) + u) ## calculate the probability for the terms appear in the document by using the Dirichlet Smoothing.\n",
        "                    else:\n",
        "                        p = (text.count(w)) / (len(text) + u) ## calculate the probability for the terms not appear in the document by using the Dirichlet Smoothing.\n",
        "                    tmp += log(p) ## calculate the log(p) of the claim.\n",
        "                f.append((eval(line)['id'], tmp))\n",
        "    f.sort(key=lambda x:x[1], reverse=True)\n",
        "    return f[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2sAZgPmqk-Q",
        "colab_type": "code",
        "outputId": "299cdd12-8358-476e-d024-83396469bd7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "index_list = [\n",
        "75397,\n",
        "150448,\n",
        "214861,\n",
        "156709,\n",
        "129629,\n",
        "33078,\n",
        "6744,\n",
        "226034,\n",
        "40190,\n",
        "76253]\n",
        "\n",
        "for index in index_list:\n",
        "    print(Subtask3_Dirichlet(index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75397\n",
            "Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "[('New_Amsterdam_-LRB-TV_series-RRB-', -54.5011749198862), ('The_Other_Woman_-LRB-2014_film-RRB-', -56.45194982259717), ('Nikolaj_Coster-Waldau', -56.45628697367302), ('Ved_verdens_ende', -56.88079383622745), ('A_Second_Chance_-LRB-2014_film-RRB-', -57.69900355637624)]\n",
            "150448\n",
            "Roman Atwood is a content creator.\n",
            "[('Joel_Spolsky', -38.748769703194654), ('Brett_Atwood', -39.25917567382504), ('Bedside_Press', -39.4132918475387), ('Only_Much_Louder', -39.605766950307526), ('Quetzal_-LRB-disambiguation-RRB-', -39.819512856347814)]\n",
            "214861\n",
            "History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.\n",
            "[('History_of_art', -106.66915996279059), ('The_arts', -123.82921183500564), ('Fine_art', -123.84171801351535), ('World_Festival_of_Black_Arts', -128.38190642559897), ('Narrative', -128.52255495085024)]\n",
            "156709\n",
            "Adrienne Bailon is an accountant.\n",
            "[('Empire_Girls-COLON-_Julissa_and_Adrienne', -31.157420177718002), ('Loni_Love', -32.20542949237431), (\"All_You've_Got\", -32.46277814814137), ('Cheetah-licious_Christmas', -32.84585103373374), ('3LW', -32.89892592204221)]\n",
            "129629\n",
            "Homeland is an American television spy thriller based on the Israeli television series Prisoners of War.\n",
            "[('List_of_Homeland_episodes', -83.94072180278707), ('Homeland_-LRB-TV_series-RRB-', -84.65794306810035), ('Homeland_-LRB-season_2-RRB-', -85.67073926345363), ('Homeland_-LRB-season_3-RRB-', -85.76722400593799), ('Homeland_-LRB-season_6-RRB-', -85.86313040268074)]\n",
            "33078\n",
            "The Boston Celtics play their home games at TD Garden.\n",
            "[('List_of_Boston_Celtics_head_coaches', -54.657341900560745), ('Boston_Celtics', -55.0182954775174), ('1974–75_Boston_Celtics_season', -55.19620400817475), ('1994–95_Boston_Celtics_season', -57.57521308368607), (\"2014–15_Providence_Friars_men's_ice_hockey_season\", -57.72007389686385)]\n",
            "6744\n",
            "The Ten Commandments is an epic film.\n",
            "[('Katherine_Orrison', -32.4893832018505), ('The_Nth_Commandment', -33.17232388589732), ('The_Ten_Commandments_-LRB-1923_film-RRB-', -33.456895868163926), ('Debra_Paget', -33.57355708459942), ('The_Sign_of_the_Cross_-LRB-1932_film-RRB-', -33.8971784397904)]\n",
            "226034\n",
            "Tetris has sold millions of physical copies.\n",
            "[('Tetris', -43.83858439274756), ('Corum_II-COLON-_Dark_Lord', -48.103612668796636), ('Sechs_Kies_discography', -48.13424356985042), ('John_C._Maxwell', -48.765852633446), ('Don_Colbert', -48.886408481069985)]\n",
            "40190\n",
            "Cyndi Lauper won the Best New Artist award at the 27th Grammy Awards in 1985.\n",
            "[('Cyndi_Lauper', -76.26935061354541), (\"She's_So_Unusual\", -91.85181059317624), ('And_We_Danced_-LRB-The_Hooters_song-RRB-', -93.54163935766078), ('Summertime-COLON-_Willie_Nelson_Sings_Gershwin', -97.25046963014594), ('List_of_awards_and_nominations_for_the_musical_Kinky_Boots', -97.3712015832044)]\n",
            "76253\n",
            "There is a movie called The Hunger Games.\n",
            "[('The_Hunger_Games', -41.509205392686134), ('The_Hunger_Games-COLON-_Catching_Fire_–_Original_Motion_Picture_Soundtrack', -42.52705345680324), ('Fictional_universe_of_The_Hunger_Games', -44.509962625728704), ('Jayme_Dee', -45.31467147525253), ('The_Hunger_Games_-LRB-disambiguation-RRB-', -45.430854323027695)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lVHdlBoleOhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}